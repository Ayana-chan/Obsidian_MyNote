
# 1

$$p(D|\mu)=\prod_{i=1}^n p(x_i|\mu) = \left({\frac 1 {\sqrt{2\pi}}}\right)^n \exp{\left\{ -\frac 1 2 \sum_{i=1}^n (x_i - \mu)^2 \right\}}$$

$$P(\mu) = \frac{1}{\sqrt{2\pi}}\exp\left\{-\frac{\mu^2}{2}\right\}$$
令$\alpha$与$\mu$无关, 则:
$$\begin{align}
p(\mu|D) 
&= \alpha \exp{\left\{ - \frac 1 2 \left[ 
\sum_{i=1}^n (x_i - \mu)^2 + \mu^2 
\right] \right\}} \\
&= \alpha^\prime \exp{\left\{ - \frac 1 2 \left[ 
(n+1)\mu^2 - 2(\sum_{i=1}^n x_i)\mu
\right] \right\}}
\end{align}$$

显然$p(D|\mu)p(\mu)$为正态分布, **假设**其分布为$N(\mu_N, \sigma_N^2)$:
$$\begin{align}
p\left(\mu|D\right)
&=\frac{1}{\sqrt{2\pi}\sigma_N}\exp\left\{
-\frac{1}{2}\left(\frac{\mu-\mu_N}{\sigma_N}\right)^2
\right\} \\
&=\frac{1}{\sqrt{2\pi}\sigma_N}\exp\left\{
-\frac{1}{2}\left(\frac{1}{\sigma_N^2}\mu^2-\frac{2\mu_N}{\sigma_N^2}\mu+\frac{\mu_N^2}{\sigma_N^2}\right)
\right\}
\end{align}$$

则$\mu$相关系数都必然相等(与$\alpha$无关), 有:
$$\begin{cases}
n + 1 = \frac 1 {\sigma_N^2} \\
\sum_{i=1}^n x_i = \frac{\mu_N}{\sigma_N^2}
\end{cases}$$

得到:
$$\begin{cases}
\mu_N = (\sum_{i=1}^n x_i) / (n + 1) \\
\sigma_N^2 = 1 / (n + 1)
\end{cases}$$

又由于
$$E(\mu|D) = \mu_N$$

因此得到
$$\hat\mu = E(\mu|D) = \frac {\sum_{i=1}^n x_i}{n + 1}$$


# 2

$$p(D|p) = (\frac p {1-p})^n (1-p)^{\sum_{i=1}^n x_i}$$

$$p(p) = \frac{1}{B(\alpha_1,\alpha_2)}p^{\alpha_1-1}(1-p)^{\alpha_2-1}$$

$$p(D|p)p(p) = \frac{1}{B(\alpha_1,\alpha_2)} p^{\alpha_1 - 1 + n} (1-p)^{\alpha_2 - 1 - n + \sum_{i=1}^n x_i}$$

$$p(D) = \int_0^1 p(D|p)p(p) 
= \frac{1}{B(\alpha_1,\alpha_2)} B(\alpha_1 + n, \alpha_2 - n + \sum_{i=1}^n x_i)$$

$$P(p|D) = p(\theta|D)=\frac{p(D|\theta)p(\theta)}{p(D)} = 
\frac {p^{\alpha_1 - 1 + n} (1-p)^{\alpha_2 - 1 - n + \sum_{i=1}^n x_i}} {B(\alpha_1 + n, \alpha_2 - n + \sum_{i=1}^n x_i)}$$

$$\begin{align}
T 
&= \frac {1} {B(\alpha_1 + n, \alpha_2 - n + \sum_{i=1}^n x_i)}\int_0^1 p \cdot p^{\alpha_1 - 1 + n} (1-p)^{\alpha_2 - 1 - n + \sum_{i=1}^n x_i} \\
&= \frac {B(\alpha_1 + n + 1, \alpha_2 - n + \sum_{i=1}^n x_i)} {B(\alpha_1 + n, \alpha_2 - n + \sum_{i=1}^n x_i)}
\end{align}$$

令$s = \alpha_1 + n$, $t = \alpha_2 - n + \sum_{i=1}^n x_i$, 则:
$$T 
= \frac {B(s + 1, t)} {B(s, t)} 
= \frac{s!(s+t-1)!}{(s-1)!(s+t)!}
= \frac {s} {s+t}$$

最终得到:
$$T = \frac {\alpha_1 + n} {\alpha_1 + \alpha_2 + \sum_{i=1}^n x_i}$$


# 3


## (1) 

$$p(x,p) = C_{10}^x p^x (1-p)^{10-x}$$

$$\ln p(x,p) = x \ln p + (10-x)\ln(1-p) + C$$

$$\frac\partial{\partial p}\ln p(x,p) = \frac x p - \frac{10 - x} {1-p}$$

$$\frac {\partial^2}{\partial p^2}\ln p(x,p) 
= -\frac x {p^2} - \frac{10 - x} {(1-p)^2} $$

得到信息量为:
$$I(p) = -n\left[ -\frac {10} {p} - \frac{10} {(1-p)}  \right]
=  \frac {10n} {p(1-p)}$$

令:
$$T_1 = \frac {\sum_{i=1}^n X_i}{10n}$$
则有:
$$Var_p(T_1) = \frac 1 {100n} Var(X) = \frac {p(1-p)} {10n} $$

于是有:
$$Var_p(T_1) = \frac 1 {I(p)}$$

因此得到有效估计:
$$T_1 = \frac {\sum_{i=1}^n X_i}{10n}$$

## (2)


$$T_2 = \frac {\sum_{i=1}^n X_i + 1} {10n+2}$$

## (3)

$$D(T_1) < D(T_2)$$

因此$T_1$更优.



# 4

## (1)

$\frac 1 3$

## (2)

$\frac 4 {15}$

# 5

$0.26$, $3.85$


# 6

$\frac 6 {35}$


# 7

$$\widehat{q}=\frac{\widehat{a}+r}{\widehat{a}+\widehat{b}+n}$$


# 8


$[2.02, 3.98]$

# 9

## (1)

$$\frac {1} {2^n B(x+1, n-x+1)}$$

## (2)

$$\frac {1} {1 + \frac {1 - \pi_0}{\pi_0 + B^\pi(x)}}$$

## (3)

$\frac {15} {23} < 1$, 不拒绝.


# 10

$$\hat \theta = \frac 1 4$$






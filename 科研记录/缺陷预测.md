
# KSETE


æ­¥éª¤ (1~3é‡å¤å¤šæ¬¡):
1. ä¸¤æ•°æ®é›†çš„æ ·æœ¬è¿›è¡Œ**æŠ½æ ·**(ä½¿å¾—æŠ½å‡ºçš„ä¸¤ä¸ªæ•°æ®é›†çš„æ ·æœ¬æ•°é‡ç›¸åŒ).
2. ç»“åˆæ‰€æŠ½æ ·çš„æ‰€æœ‰æ•°æ®, **æ˜ å°„**(ç”¨æ ¸è°±åµŒå…¥)å‡ºæ–°çš„"æºæ•°æ®"å’Œ"ç›®æ ‡æ•°æ®".
3. å¯¹æ–°æ•°æ®è¿›è¡Œ**æ™®é€šé€»è¾‘å›å½’**æ¥åˆ†ç±», å¾—åˆ°é¢„æµ‹ç»“æœ.
4. **ç»¼åˆ**æ¯æ¬¡æŠ½æ ·çš„é¢„æµ‹ç»“æœ, å¾—åˆ°æœ€ç»ˆé¢„æµ‹ç»“æœ.

ç”±äºæ˜ å°„è¿‡ç¨‹éœ€è¦åŒæ—¶ç»“åˆæºæ•°æ®å’Œç›®æ ‡æ•°æ®, å› æ­¤**å¼‚æ„**ä¿¡æ¯æ˜¯åœ¨*æ˜ å°„*å½“ä¸­å¾—åˆ°å¤„ç†çš„, è€Œåé¢çš„*é€»è¾‘å›å½’å­¦ä¹ *å°±**ä¸è€ƒè™‘å¼‚æ„é—®é¢˜**äº†.

ä½†æ˜¯, ç°åœ¨çš„æƒ…å†µæ˜¯, *åº¦é‡å…ƒä½¿ç”¨åŒä¸€ä¸ªè½¯ä»¶æå–*, ä¹Ÿå°±æ˜¯è¯´**ç‰¹å¾éƒ½æ˜¯å®Œå…¨ä¸€æ ·çš„**, åªä¸è¿‡**æ•°æ®çš„åˆ†å¸ƒä¸åŒ**. KSETEè™½ç„¶ä¹Ÿèƒ½å¤„ç†æ•°æ®åˆ†å¸ƒå·®åˆ«, ä½†å®ƒä¹Ÿèƒ½å¤„ç†ç‰¹å¾çš„ä¸åŒ, èƒ½åŠ›èŒƒå›´è¶…è¿‡äº†éœ€æ±‚. æ¢å¥è¯è¯´, ç›®å‰çš„éœ€æ±‚ä¸åœ¨KSETEçš„è®ºåŸŸå†….

ç›®å‰çš„éœ€æ±‚æƒ…å†µ:
- ç‰¹å¾ä¸€æ ·, ä»»åŠ¡ä¸€æ ·, **æ•°æ®åˆ†å¸ƒä¸ä¸€æ ·**.
- æ— è®ºæ˜¯*ä¸åŒçš„é¡¹ç›®*ä¹‹é—´, è¿˜æ˜¯*é¡¹ç›®çš„ä¸¤ä¸ªç‰ˆæœ¬*ä¹‹é—´, éƒ½æœ‰æ•°æ®åˆ†å¸ƒçš„ä¸åŒ. ä¾‹å¦‚, ä¸€ä¸ªè½¯ä»¶çš„<u>æ–°ç‰ˆæœ¬</u>ä¿®å¤äº†è‹¥å¹²bug, é‚£ä¹ˆ<u>ç›¸è¾ƒäºæ—§ç‰ˆæœ¬</u>æ¥è¯´, $åº¦é‡å…ƒ \rightarrow æœ‰æ— bug$ çš„<u>æ˜ å°„æƒ…å†µå°±ä¼šå‘ç”Ÿæ”¹å˜</u>(å³ä½¿ä»£ç åŸºæœ¬æ²¡æ”¹).

ç›´æ¥ç®€å•çš„**å¾®è°ƒ**(å³æ‹¿æºæ•°æ®è®­ç»ƒä¸€ä¸ªæ¨¡å‹, ç„¶åå¡å…¥å°‘é‡æ–°æ•°æ®è¿›è¡Œå¾®è°ƒè®­ç»ƒ), åˆ™éœ€è¦å°‘é‡çš„*å¸¦labelçš„ç›®æ ‡æ•°æ®*, æˆ–è€…è¯´*ç›®æ ‡é¡¹ç›®çš„éƒ¨åˆ†bugä¿¡æ¯*. å¦å¤–, è¿™ä¹Ÿåº”è¯¥è¦æ±‚è¾ƒå¤§çš„æºæ•°æ®è§„æ¨¡. 
- å¥½å¤„æ˜¯èƒ½åˆ©ç”¨å¼€æºæ•°æ®é›†;
- åå¤„æ˜¯è¦æ±‚æä¾›ç›®æ ‡é¡¹ç›®<u>éƒ¨åˆ†æ¨¡å—</u>çš„ä¸€å®šæ•°é‡çš„bugä¿¡æ¯.
- è·¨æ¨¡å—ä¹Ÿæœ‰æ•°æ®åˆ†å¸ƒä¸ä¸€è‡´çš„é—®é¢˜?

TODO: å¯¹äºbugæ•°æ®é›†æ¥è¯´, ç›¸æ¯”äºå‡ºç°è¯¯æ ‡, å…¶å‡ºç°**æ¼æ ‡**çš„å¯èƒ½æ€§æ›´å¤§, ä»¥è‡³äºç”šè‡³è®©å…¶è‡ªå·±é¢„æµ‹è‡ªå·±éƒ½å¯èƒ½å¯ä»¥æ•´å‡ºç‚¹å„¿æ„ä¹‰æ¥. å¦å¤–, åæ­£å¾®è°ƒéƒ½è¦æ±‚è¦ç”¨ç›®æ ‡æ•°æ®äº†, é‚£ä¹ˆåœ¨æ•°æ®é‡è¶³å¤Ÿçš„æƒ…å†µä¸‹æ˜¯ä¸æ˜¯èƒ½å¹²è„†å¼„æˆè‡ªå·±é¢„æµ‹è‡ªå·±. å¦‚ä½•æ¶ˆè§£æ¼æ ‡å¸¦æ¥çš„å½±å“? æ˜¯å¦æœ‰è‡ªå·±é¢„æµ‹è‡ªå·±çš„ç ”ç©¶? å¦å¤–æ ‡æ³¨çš„æ—¶å€™, æœ‰äº›ä¸œè¥¿éƒ½ä¸çŸ¥é“èƒ½ä¸èƒ½è§†ä¸ºbug, è€Œå¼€æºæ•°æ®é›†çš„è®ºæ–‡é‡Œé¢ç›´æ¥å¿½ç•¥äº†è¿™äº›ä¸œè¥¿(åŒ…æ‹¬éš¾ä»¥å®šä½çš„bug).
- ä¸å®Œå…¨æ ‡æ³¨??


# 2025.3.18

KSETEçš„ä¸€ä¸ªBaseline, 2018: Heterogeneous Defect Prediction
- é€šè¿‡åˆ†æè®­ç»ƒé›†, é€‰å–å‡ºé‡è¦çº§åˆ«å‰15%çš„ç‰¹å¾
- åˆ†æè®­ç»ƒé›†å’Œç›®æ ‡é›†çš„ç‰¹å¾ç›¸å…³æ€§, è¿›è¡Œç‰¹å¾é—´çš„è”åˆåŒ¹é….
- åŒ¹é…å®Œæˆä¹‹å, å°±æ˜¯ç®€å•çš„åŒæ„æ•°æ®é›†é¢„æµ‹, ç›´æ¥ä½¿ç”¨å¸¸è§åˆ†ç±»å™¨.

---

**Tabular Data (è¡¨æ ¼æ•°æ®)** 

2022: Why do tree-based models still outperform deep learning on tabular data?
- å¯è§é‚£æ—¶å€™ä¸å¦‚ç›´æ¥XGBoostç­‰åŸºäºæ ‘çš„æ¨¡å‹ (æ³¨: XGBoostæ˜¯2016å¹´çš„è®ºæ–‡).
![](assets/Pasted%20image%2020250317222553.png)

2022: Revisiting Deep Learning Models for Tabular Data (FT-transformer)
- ä½¿ç”¨äº†Feature Tokenizer æ¥æŠŠè¡¨æ ¼æ•°æ®å˜æˆtoken. ä¸€ä¸ªç‰¹å¾çš„æ‰€æœ‰æ•°æ®ç»„æˆäº†ä¸€ä¸ªtoken; æˆ–è€…è¯´, ä¸€ä¸ªæ ·æœ¬çš„æ‰€æœ‰ç‰¹å¾æ•£è½åœ¨å„ä¸ªtokené‡Œé¢.
- åŸºäºTransformer.
- è¢«æŒ‡æ˜ä¸å¦‚XGBoostç­‰åŸºäºæ ‘çš„æ¨¡å‹.
![](assets/Pasted%20image%2020250317222533.png)

2024: From Supervised to Generative: A Novel Paradigm for Tabular Deep Learning with Large Language Models (TabFM)
- è¿™æ˜¯ä¸€ä¸ªç”¨äº<u>è·¨é¢†åŸŸæ•°æ®é›†</u>çš„å·¥ä½œ.
- å¯¹è¡¨æ ¼æ•°æ®çš„æ¯ä¸ªæ ·æœ¬(æ¯ä¸€è¡Œ), éƒ½ç”Ÿæˆä¸€å¥è¯: æ•°æ®èƒŒæ™¯ + æ¯ä¸ªç‰¹å¾çš„æ„æ€å’Œå€¼ + æœ€ç»ˆç»“æœçš„æ„æ€å’Œå€¼.
- ä½¿ç”¨GTL(Generative Tabular Learning)æœºåˆ¶, æŠŠLLMè½¬å˜æˆTabFM(Tabular Foundation Models). è®ºæ–‡å®éªŒç”¨çš„æ˜¯llama2.
- æ¯”GPT4å·®ä¸€ç‚¹ä½†æ¥è¿‘.
![](assets/Pasted%20image%2020250317232413.png)

---

2022: Within-Project Defect Prediction of Infrastructure-as-Code Using Product and Process Metrics
- é’ˆå¯¹çš„æ˜¯è„šæœ¬æ–‡ä»¶.
- å¯¹åº¦é‡å…ƒ, ä½¿ç”¨ å†³ç­–æ ‘ã€é€»è¾‘å›å½’ã€æœ´ç´ è´å¶æ–¯ã€éšæœºæ£®æ—å’Œæ”¯æŒå‘é‡æœº è¿›è¡Œé¢„æµ‹, å‘ç°éšæœºæ£®æ—æœ€å¥½.

2020: Deep Semantic Feature Learning for Software Defect Prediction
- æ–‡ä»¶çº§æˆ–åŸºäºå˜æ›´(commit).
- åŸºäºè¯­æ³•æ ‘æå–æ•°æ®.
- ä½¿ç”¨DBNé¢„æµ‹.

---

TODO: XGBoostå’Œéšæœºæ£®æ—çš„æ³›åŒ–æ€§é—®é¢˜.

TODO: 2024(IEEE Access): Tabular Data Classification and Regression: XGBoost or Deep Learning With Retrieval-Augmented Generation
- ç»“æœè¡¨æ˜ï¼Œå…·æœ‰RAGæˆåˆ†çš„TabRåœ¨åˆ†ç±»æ–¹é¢ä¼˜äºXGBoostï¼Œæœ‰æ•ˆåœ°ç®¡ç†äº†ä¸ç¡®å®šæ€§ã€‚ç„¶è€Œï¼Œåœ¨å›å½’ä»»åŠ¡ä¸­ï¼ŒXGBoostç»§ç»­ä¼˜äºTabRã€‚

TODO: 2024: LLM2Vec: Transforming Tabular Data to Vector Space with Large Language Models

TODO 2025(æ™®é€šç»¼è¿°æ–‡ç« ): DeepÂ LearningÂ withinÂ TabularÂ Data: Foundations, Challenges, Advances and Future Directions


# 2025.3.25

SIGIR 2024: Large Language Models for Tabular Data: Progresses and Future Directions
- æ•°æ®åº“é‚£ç§å…³ç³»æ˜ç¡®çš„è¡¨(å¯ä»¥è¢«sqlå’Œpandasæ“ä½œçš„, ç”šè‡³æœ‰å¤–é”®çš„)å«åšç»“æ„åŒ–è¡¨(structured tables); wordæ–‡æ¡£å’Œlatexå‡ºç°çš„è¡¨æ˜¯semi-structured tables; å›¾ç‰‡(RGBçŸ©é˜µ)åˆ™æ˜¯image tables.
- TODO refs

Trans. Mach. Learn. Res.Â 2024: Large Language Models (LLMs) on Tabular Data: Prediction, Generation, and Understanding - A Survey
- è¡¨æ ¼æ•°æ®ï¼Œé€šå¸¸ç§°ä¸ºç»“æ„åŒ–æ•°æ®ï¼Œæ˜¯æŒ‡ç»„ç»‡æˆè¡Œå’Œåˆ—çš„æ•°æ®ï¼Œå…¶ä¸­æ¯åˆ—ä»£è¡¨ä¸€ä¸ªç‰¹å®šç‰¹å¾ã€‚
- TODO

KDD 2024: From Supervised to Generative: A Novel Paradigm for Tabular Deep Learning with Large Language Models (TabFM)
- è¿™æ˜¯ä¸€ä¸ªå¼ºè°ƒäº†<u>è·¨é¢†åŸŸæ•°æ®é›†</u>çš„å·¥ä½œ. å…¶introductioné‡Œé¢éƒ½æ²¡æåˆ°å…¶ä»–è·¨é¢†åŸŸæ•°æ®é›†çš„ä»»åŠ¡. åº”è¯¥æ˜¯ä¸ºäº†é¿å…åº”ç”¨æ—¶ä¸­ä¸ºå•ä¸€é¢†åŸŸè€Œé‡æ–°è®­ç»ƒ.
- TODO: å¦‚æœæ¨¡å‹å¼€æºçš„è¯è¯´ä¸å®šèƒ½ç›´æ¥æ‹¿æ¥ç”¨.
- å¯¹è¡¨æ ¼æ•°æ®çš„æ¯ä¸ªæ ·æœ¬(æ¯ä¸€è¡Œ), éƒ½ç”Ÿæˆä¸€å¥è¯: æ•°æ®èƒŒæ™¯ + æ¯ä¸ªç‰¹å¾çš„æ„æ€å’Œå€¼ + æœ€ç»ˆç»“æœçš„æ„æ€å’Œå€¼.
- ä½¿ç”¨GTL(Generative Tabular Learning)æœºåˆ¶, æŠŠLLMè½¬å˜æˆTabFM(Tabular Foundation Models). è®ºæ–‡å®éªŒç”¨çš„æ˜¯llama2.
- æ¯”GPT4å·®ä¸€ç‚¹ä½†æ¥è¿‘.
- æµ‹è¯•çš„æ—¶å€™, ä½¿ç”¨GPT4ç”Ÿæˆä»»åŠ¡èƒŒæ™¯å’Œç‰¹å¾ä¿¡æ¯çš„æ–‡æœ¬.
- åŒé¢†åŸŸæ•°æ®é›†é¢„æµ‹ç§°ä½œin-domain transfer, å¦åˆ™ä¸ºin-domain transfer. åŒé¢†åŸŸæŒ‡çš„æ˜¯æµ‹è¯•é›†é‡Œé¢å­˜åœ¨äºè®­ç»ƒé›†æœ‰é¢†åŸŸé‡åˆçš„æ•°æ®.
![](assets/Pasted%20image%2020250325130510.png)

AISTATS 2023 (CCF C): TabLLM: Few-shot Classification of Tabular Data with Large Language Models
- è¡¨æ ¼æ•°æ®ç¼ºä¹å±€éƒ¨æ€§ï¼ŒåŒ…å«æ··åˆæ•°æ®ç±»å‹ï¼Œåˆ—çš„æ•°é‡é€šå¸¸ä¸æ–‡æœ¬æˆ–å›¾åƒæ•°æ®ä¸­çš„ç‰¹å¾æ•°é‡ç›¸æ¯”ç›¸å½“å°ã€‚
- ç›¸å…³å·¥ä½œéƒ¨åˆ†çš„æœºå™¨å­¦ä¹ éƒ¨åˆ†ä¸­, åœ¨22å¹´è®¤ä¸ºæ ‘æ¨¡å‹æ›´ä¼˜çš„è®ºæ–‡å‘è¡¨ä¹‹å, ä½œè€…åªè®¤å¯TabPFN(2022)è¶…è¿‡äº†æ ‘æ¨¡å‹.
- å·¥ä½œé‡ç‚¹åœ¨äº**åºåˆ—åŒ–**. TabLLMæ¦‚å¿µä¸å…·ä½“LLMå’Œå¾®è°ƒæ–¹æ³•æ— å…³, è®ºæ–‡çš„LLMä½¿ç”¨11bçš„T0 encoder-decoder model (HuggingFace implementation) (ç†ç”±: It was trained on a large variety of task-specific prompts); å¾®è°ƒæ–¹æ³•ä½¿ç”¨T-Few(ä½¿ç”¨äº†kä¸ªå°‘é‡æ ‡è®°æ•°æ®); promptä½¿ç”¨PromptSource framework.
- æœ€ä½³çš„åºåˆ—åŒ–æ–¹å¼æ˜¯ **Text Template**: An textual enumeration of all features as â€œThe column name is value.â€ ä¸è¿‡åˆ—åéœ€è¦è¢«ä¿®æ”¹æˆå¯ä»¥ç›´æ¥ç†è§£å…¶å«ä¹‰çš„è¯, ä¾‹å¦‚`hours_per_week`ç”šè‡³`hours` éœ€è¦è¢«æ”¹æˆ `work hours per week`.
![](assets/Pasted%20image%2020250325121404.png)
- Text Templateç¤ºä¾‹:
![](assets/Pasted%20image%2020250325124943.png)
- "We used 20% of the data as a test set" å®éªŒåº”è¯¥æ˜¯åœ¨åŒä¸€ä¸ªæ•°æ®é›†é‡Œé¢, ä¸€éƒ¨åˆ†é¢„æµ‹å¦ä¸€éƒ¨åˆ†.
- åªæœ‰å°‘æ ·æœ¬ä¸‹å ä¼˜åŠ¿:
![](assets/Pasted%20image%2020250325121719.png)
![](assets/Pasted%20image%2020250325124333.png)
- ç»“è®º: ç›´æ¥ä½¿ç”¨å®Œå…¨æ²¡å¾®è°ƒè¿‡çš„æˆ–ç®€å•å¾®è°ƒçš„æ™®é€šLLM, ä¹Ÿèƒ½å‘æŒ¥è¶³å¤Ÿå¥½çš„æ€§èƒ½, åªè¦è¾“å…¥æ˜¯text templateè¿™æ ·çš„ç®€å•å½¢å¼. åº”è¯¥æ˜¯æ¨¡å‹ç›´æ¥å°è¯•å¯¹åˆ—åè¿›è¡Œç†è§£å’Œæ€è€ƒ.


# 2025.4.1

KDD 2024: From Supervised to Generative: A Novel Paradigm for Tabular Deep Learning with Large Language Models (TabFM)
- è®ºæ–‡pdfå’Œå®˜ç½‘å«åšTowards Foundation Models for Learning on Tabular Data.
- [å¾®è½¯äºšæ´²ç ”ç©¶é™¢å®˜ç½‘](https://www.microsoft.com/en-us/research/publication/towards-foundation-models-for-learning-on-tabular-data/)
- Data and code will be open sourced. ç›®å‰åº”è¯¥å°šæœªå¼€æº.

Trans. Mach. Learn. Res.Â 2024: Large Language Models (LLMs) on Tabular Data: Prediction, Generation, and Understanding - A Survey
- è¡¨æ ¼æ•°æ®ï¼Œé€šå¸¸ç§°ä¸ºç»“æ„åŒ–æ•°æ®ï¼Œæ˜¯æŒ‡ç»„ç»‡æˆè¡Œå’Œåˆ—çš„æ•°æ®ï¼Œå…¶ä¸­æ¯åˆ—ä»£è¡¨ä¸€ä¸ªç‰¹å®šç‰¹å¾ã€‚
- ä½¿ç”¨LLMè¿›è¡Œè¡¨æ ¼åºåˆ—åŒ–ä¸å¤ªè¡Œçš„å…³é”®åŸå› æ˜¯, ä¼šæœ‰å¹»è§‰, ç”Ÿæˆä¸æ­£ç¡®çš„ä¸œè¥¿.
- å¤šä¸ªå·¥ä½œè¡¨æ˜, åºåˆ—åŒ–æœ€å¥½å°±æ˜¯ **"column name is value"**.
- æŠŠLLMçš„è¾“å‡ºæ˜ å°„åˆ°æƒ³è¦çš„è¾“å‡ºæ ‡ç­¾çš„è¿‡ç¨‹ç§°ä½œtarget augmentation(ç›®æ ‡å¢å¼º)(ä¸‹è¡¨ä¸ºå„ä¸ªæ–¹æ³•ä¾‹å­). ä¸ºäº†è®¡ç®—å¥½ä¸€äº›æŒ‡æ ‡(AUCROCæˆ–AUCPR)ç­‰, å¯èƒ½æœ‰ä¸ªéœ€æ±‚æ˜¯è¦æ±‚è¾“å‡ºä¸æ˜¯0-1è€Œæ˜¯æ¦‚ç‡, Verbalizerå¯ä»¥åšåˆ°, æå¤æ‚çš„UniPredictä¹Ÿè¡Œ.
![](assets/Pasted%20image%2020250329200113.png)
- åŒ»å­¦æ•°æ®åŒ…å«äº†ä¸æ—¶é—´æ¨ç§»å˜åŒ–çš„ä¸œè¥¿, å˜é‡é—´é«˜åº¦å…³è”(åŒ…æ‹¬ç¼ºå¤±), è¿˜æœ‰ç¬”è®°ç­‰éç»“æ„åŒ–æ•°æ®, å› æ­¤LLMç›´æ¥æ¯”æ ‘å ä¼˜.

Corr abs 2023 <u>è¿˜æ²¡å‘</u>: Towards better serialization of tabular data for few-shot classification with large language models

NeurIPS 2022: Lift: Language-interfaced fine-tuning for non-language machine learning tasks.
- å¼€æº
- Language-Interfaced Fine-Tuning (LIFT)
- ç›®çš„æ˜¯: åœ¨å®Œå…¨ä¸æ”¹å˜æ¶æ„æˆ–æŸå¤±å‡½æ•°çš„æƒ…å†µä¸‹, ä½¿ç”¨å¾®è°ƒè®©LLMé€‚åº”éè¯­è¨€ä»»åŠ¡. æµ‹è¯•ä¸­åŒ…å«äº†tabular data, åŒ…å«äº†åˆ†ç±»å’Œå›å½’.
- æåˆ°äº†å®ƒçš„ä¼˜ç‚¹æ˜¯å¯ä»¥ä½¿ç”¨åŸå§‹æ•°æ®, ä¸éœ€è¦åƒä¸€äº›åŸºçº¿æ¨¡å‹ä¸€æ ·éœ€è¦ç‰¹å¾ç¼©æ”¾å’Œå½’ä¸€åŒ–.
- æ•°æ®åºåˆ—åŒ–:
![](assets/Pasted%20image%2020250329221933.png)
- åˆ†ç±»ä»»åŠ¡: åœ¨ç±»åˆ«æ•°è¾ƒé«˜æ—¶, æ€§èƒ½å˜å·®. ä¸è¿‡ç›®å‰çš„ç¼ºé™·é¢„æµ‹éœ€æ±‚çš„ç±»åˆ«æ•°ä»…ä¸º2. ä½†æ˜¯, ç±»åˆ«æ•°ä½æ—¶, ä¹Ÿåªæ˜¯ä¸åŸºçº¿æ¨¡å‹**ç›¸å½“**. é«˜ç»´(featureæ•°è¾ƒé«˜)æ—¶æ€§èƒ½ä¹Ÿèƒ½ä¿æŒ.
![](assets/Pasted%20image%2020250329221602.png)
- ä¸è¿‡, åœ¨è¡¨æ ¼æ•°æ®ä¸Š, å’Œå½“æ—¶çš„å…¶ä»–å¤§æ¨¡å‹æ¯”èµ·æ¥, å¯ä»¥è¯´æ˜¯æœ€å¥½:
![](assets/Pasted%20image%2020250329222846.png)
- å›å½’ä»»åŠ¡: åœ¨ä½çº¬çš„æ—¶å€™æ€§èƒ½å°±ä¸è¡Œ, é«˜ç»´çš„æ—¶å€™ç›´æ¥è¯´æ˜¯"æ— æ•ˆ".
- ç›®å‰çœ‹æ¥, èµ·ç å°±è¾“å…¥æ¥è¯´, TabLLMå·²ç»æ¯”è¿™LIFTä¼˜ç§€äº†.

ICML 2023: XTab: Cross-table Pretraining for Tabular Transformers
- [GitHub - BingzhaoZhu/XTab](https://github.com/BingzhaoZhu/XTab)
- å’ŒTabPFNåŒä¸€æ—¶é—´, å£°ç§°è‡ªå·±çš„æ¨ç†å¤æ‚åº¦ä¸è¡¨å¤§å°æ— å…³, æ‰€ä»¥æ¯”TabPFNæ›´é€‚åˆå¤§è¡¨. ä½†æ˜¯<u>æ²¡å’ŒTabPFNæ¯”</u>.
- å¼ºè°ƒäº†cross-table(è·¨è¡¨), å¹¶ä¸”å¼ºè°ƒè‡ªå·±èƒ½è·¨é¢†åŸŸ.
- å®éªŒä¸­, CatBoostä¸€ç›´æœ€å¼º.

ICLR 2023: TabPFN: A transformer that solves small tabular classification problems in a second
- [GitHub - PriorLabs/TabPFN: âš¡ TabPFN: Foundation Model for Tabular Data âš¡](https://github.com/PriorLabs/TabPFN)
- åœ¨TabLLMè®ºæ–‡çš„æµ‹è¯•é‡Œé¢è¡¨ç°æœ€å¥½, åœ¨GTLè®ºæ–‡çš„æµ‹è¯•é‡Œé¢ä¹Ÿè¶³å¤Ÿä¼˜ç§€(æ„Ÿè§‰æ˜¯é™¤GTLæœ¬èº«å’ŒGPT4å¤–æœ€å¥½çš„).
![](assets/Pasted%20image%2020250325121719.png)
- Prior-Data Fitted Network (PFN), å‡ºè‡ªè®ºæ–‡ ICLR 2022: Transformers Can Do Bayesian Inference. ä¸‹å±‚æ˜¯ä¸€ä¸ªç‰¹æ®Šçš„Transformer.
- å¼ºè°ƒé€Ÿåº¦, åœ¨å•æ ¸CPUå¹³å‡è·‘4ç§’å°±æ¯”å…¶ä»–baselineçš„ä¸€å°æ—¶è¦å¥½.
- å¼ºè°ƒå°æ•°æ®é›†(1000æ ·æœ¬, 100ç‰¹å¾, 10åˆ†ç±»)(æ·±åº¦å­¦ä¹ åœ¨è¿™ç§æ•°æ®é›†ä¸Šè¡¨ç°ä¹Ÿè¾ƒå·®). è®­ç»ƒæ—¶é—´ä¸å†…å­˜ å’Œ æ ·æœ¬è¾“å…¥ æ˜¯$O(n^2)$å…³ç³».
- ä»ä¸‹å›¾å¯ä»¥çœ‹å‡º, å®ƒåº”è¯¥æ²¡æœ‰è¿ç§»å­¦ä¹ çš„èƒ½åŠ›, è¾“å…¥çš„æ•°æ®é›†åº”å½“å’Œç›®æ ‡é›†åŒåˆ†å¸ƒ.
![](assets/Pasted%20image%2020250331215539.png)
- èŠ±äº†0.62ç§’GPUçš„TabPFN, ä¸å…¶ä»–èŠ±äº†ä¸åˆ°ä¸€å°æ—¶çš„å„ä¸ªbaselineè¿›è¡Œæ¯”è¾ƒ:
![](assets/Pasted%20image%2020250331213039.png)
- TabPFN + AutoGluonæ˜¯æœ€ä¼˜çš„, å®ƒæ˜¯ç›´æ¥æŠŠäºŒè€…çš„é¢„æµ‹ç»“æœå–äº†å¹³å‡å€¼(å› ä¸ºå‘ç°TabPFNä¸AutoGluonçš„<u>é”™è¯¯ç›¸å…³æ€§</u>è¾ƒä½, å³å‘ç°å®ƒä»¬å„è‡ªè¡¨ç°è‰¯å¥½çš„æ•°æ®é›†æ˜¯å¾ˆä¸ä¸€æ ·çš„, äºæ˜¯å–å¹³å‡ä»¥å‡å°‘çŠ¯é”™).
![](assets/Pasted%20image%2020250331205816.png)
- åœ¨æœ‰åˆ†ç±»ç‰¹å¾å’Œç¼ºå¤±å€¼çš„æ—¶å€™**æ€§èƒ½è¾ƒå·®**.
![](assets/Pasted%20image%2020250331212731.png)
- ä½¿ç”¨EQæ•°æ®é›†æ¥å°è¯•TabPFN, åˆ‡åˆ†æ•°æ®é›†(åˆ†å±‚æŠ½æ ·)è¿›è¡Œé¢„æµ‹, æ€§èƒ½å¦‚ä¸‹:
```txt
ROC AUC: 0.8721301020408163
Accuracy: 0.7901234567901234
F1: 0.7384615384615385
```


---

Deep neural networks and tabular data: A survey.
- TODO

ICLR 2023: Transfer Learning with Deep Tabular Models
- æ¢ç´¢å·²æœ‰è¡¨æ ¼æ¨¡å‹(åŒ…æ‹¬æ·±åº¦å­¦ä¹ çš„)åœ¨**è¿ç§»å­¦ä¹ **ä¸Šçš„ä¼˜åŒ–ä¸æ€§èƒ½æ½œåŠ›.
- TODO


# 2025.4.15

transferable tabular models

TabPFNåœ¨44æ•°æ®é›†ä¸Šæ€§èƒ½æ¯”KSETEå¥½, ä½†æ˜¯ä¼šå‡ºç°é¢„æµ‹æ¦‚ç‡å…¨éƒ¨å°äº0.5å¯¼è‡´è¾“å‡ºå…¨0çš„æƒ…å†µ. æ­¤æ—¶çš„AUCä¾ç„¶ç‰¹åˆ«é«˜, ä¹Ÿè®¸æ”¹æ”¹thresholdæœ‰å¯èƒ½æ›´å¥½ç”¨? ä¾‹å¦‚`prj-bug_cptool -> ZY4000_cptool`, çœŸå®labelä¸º1çš„è¯, é¢„æµ‹çš„æ¦‚ç‡å‡ ä¹éƒ½åœ¨0.3ä»¥ä¸Š.

è™½ç„¶æ²¡æœ‰å¯¹æ¯”ï¼Œä½†TabPFNåœ¨å•æ•°æ®é›†å†…é¢„æµ‹çš„æƒ…å†µä¸‹æ€§èƒ½ä¸€ç›´éå¸¸é«˜ã€‚labelä¸º0çš„ï¼Œé¢„æµ‹æ¦‚ç‡å€¼ä¹Ÿä¼šç‰¹åˆ«å°ã€‚

è¿ç§»å­¦ä¹ æ›´å€¾å‘äºæ‹¿åŸå§‹çš„å å¤šæ•°çš„æ•°æ®è®­ç»ƒ, ç„¶åå†åŠ ä¸Š<u>ç›®æ ‡æ•°æ®é›†</u>çš„å°‘æ•°<u>å¸¦æ ‡ç­¾çš„æ ·æœ¬</u>åšè¿ç§»å­¦ä¹ , ä»¥æ›´å¥½åœ°é¢„æµ‹ç›®æ ‡æ•°æ®é›†. åœ¨å¤§æ¨¡å‹ä¸­ä½“ç°ä¸º ä½¿ç”¨ç›®æ ‡é›†çš„ä¸€éƒ¨åˆ†è¿›è¡Œ**å¾®è°ƒ**. å¦‚æœæ²¡æœ‰è¿™å±äºç›®æ ‡æ•°æ®é›†çš„å°‘æ•°æ ·æœ¬çš„è¯, æ˜¯ä¸€ç§**zero-shot(é›¶æ ·æœ¬)** çš„é¢„æµ‹. KSETEå°±æ˜¯é›¶æ ·æœ¬çš„, å®ƒç›¸å½“äºç›´æ¥ä»ç›®æ ‡é›†çš„ç‰¹å¾åˆ†å¸ƒå­¦ä¹ äº†è¿ç§»çŸ¥è¯†, è€Œä¸éœ€è¦ç›®æ ‡é›†çš„label.
- è€ƒè™‘å¾®è°ƒçš„æƒ…å†µä¸‹, TabPFNä¹Ÿèƒ½çœ‹åšè¿ç§»å­¦ä¹ äº†, æ–°æŒ‡å®šçš„å¸¦labelçš„æ•°æ®é›†å°±ç›¸å½“äºå¾®è°ƒæ•°æ®é›†. ä¸è¿‡TabPFNåŸºç¡€çŸ¥è¯†æ¥è‡ªäºå¤§é‡çš„é¢„è®­ç»ƒ, å› æ­¤ä¸å¥½æŒ‡å®šæŸä¸ªæ•°æ®é›†å•ç‹¬ä½œä¸ºæ¨¡å‹çš„åŸºç¡€çŸ¥è¯†.
- æˆ–è€…è¯´ä¸Šè¶…å¤§é¢„è®­ç»ƒé›†çš„ä¸œè¥¿éƒ½èƒ½ç®—è¿ç§»å­¦ä¹ , åŒ…æ‹¬TabLLM.

NatureÂ volumeÂ 637,Â pages319â€“326 (2025): Accurate predictions on small data with a tabular foundation model
- è¿™æ˜¯**TabPFN**çš„æ–°è®ºæ–‡, å‘åˆ°äº†Natureä¸Š, åšäº†è¿›ä¸€æ­¥çš„ä¼˜åŒ–. ä¸Šé¢çš„ä»£ç ä½¿ç”¨çš„å°±æ˜¯ä¼˜åŒ–åçš„2.0ç‰ˆæœ¬.
- åˆ©ç”¨post hoc ensembling (PHE), åšå‡ºTabPFN(PHE), å¢å¼ºäº†åŠŸèƒ½. [GitHub - PriorLabs/tabpfn-extensions: Community extensions for TabPFN - the foundation model for tabular data. Built with TabPFN! ğŸ¤—](https://github.com/PriorLabs/tabpfn-extensions). è·‘çš„æ—¶å€™æœ‰è‹¥å¹²è­¦å‘Š: `D:\miniconda3\envs\tabular\Lib\site-packages\sklearn\preprocessing\_encoders.py:246: UserWarning: Found unknown categories in columns [0] during transform. These unknown categories will be encoded as all zeros`. åœ¨å¼€æºçš„è½¯ä»¶ç¼ºé™·æ•°æ®é›†ä¸Šè·‘å‡ºæ¥çš„æ€§èƒ½, ç›¸å¯¹æ™®é€šTabFPNçš„æ€§èƒ½æ¥è¯´, åªæ˜¯éšæœºä¸Šä¸‹æµ®åŠ¨, <u>çœ‹ä¸å‡ºæ˜¾è‘—æå‡</u>. TODO: åœ¨ç§æœ‰æ•°æ®é›†ä¸Šè·‘å‡ºé—®é¢˜, debugging.

NeurIPS 2022: Transtab: Learning transferable tabular transformers across tables.
- ä»£ç : [GitHub - RyanWangZf/transtab: NeurIPS'22 | TransTab: Learning Transferable Tabular Transformers Across Tables](https://github.com/RyanWangZf/transtab)
- æ–‡æ¡£: [Welcome to transtab documentation! â€” transtab alpha documentation](https://transtab.readthedocs.io/en/latest/)
- å¼ºè°ƒè‡ªå·±å¯¹ç‰¹å¾æ˜¯å¦ç›¸åŒæ²¡æœ‰è¦æ±‚. å¯ä»¥åœ¨ä¸åŒç‰¹å¾ç»“æ„çš„è¡¨ä¸Šè¿›è¡Œé¢„è®­ç»ƒ.
![](assets/Pasted%20image%2020250413151200.png)
- å¯¹ä¸åŒç§ç±»çš„ç‰¹å¾ä½¿ç”¨ä¸åŒçš„è¾“å…¥æ–¹å¼: åˆ†ç±»ç‰¹å¾é€šè¿‡ç®€å•ç»„æˆå¥å­å†ç¼–ç ; äºŒåˆ†ç‰¹å¾åˆ™åœ¨å€¼1çš„æƒ…å†µä¸‹ ç¼–ç ç‰¹å¾å, å¦åˆ™ä¸å¤„ç†; æ•°å­—ç±»å‹åˆ™æŠŠç‰¹å¾åç¼–ç åæŠŠæ•°å€¼ä¹˜å…¥ç¼–ç .
![](assets/Pasted%20image%2020250413201200.png)
![](assets/Pasted%20image%2020250413201705.png)
- æ²¡å’ŒCatBoostæ¯”; æ¯”XGBoost<u>å¥½ç‰¹åˆ«å¤š</u>
- å®éªŒé‡Œä½¿ç”¨å¤šä¸ª<u>ä¸åŒçš„ç™Œç—‡å®éªŒ</u>ç»“æœ(<u>æœ‰é‡åˆç‰¹å¾</u>)ä½œä¸ºæ•°æ®é›†(ç›¸å½“äºéƒ½åŒæ ·æ˜¯ç™Œç—‡é¢†åŸŸ).
- ä½¿ç”¨ç›®æ ‡æ•°æ®é›†çš„è‹¥å¹²æ ·æœ¬è¿›è¡Œè¿ç§»å­¦ä¹ .
- æœ‰ä¸€å®šçš„é›¶æ ·æœ¬é¢„æµ‹èƒ½åŠ›.
- ä¸¤ä¸ªæ•°æ®é›†å»é¢„è®­ç»ƒä¹Ÿåªéœ€è¦å‡ åç§’çš„æ—¶é•¿(æ²¡æœ‰æä¾›è¶…å¤§é¢„è®­ç»ƒåçš„æ¨¡å‹).
- ä¸çŸ¥é“ä¸ºä»€ä¹ˆç›®å‰çœ‹çš„è®ºæ–‡é™¤äº†XTabå¥½åƒéƒ½æ²¡æŠŠè¿™ä¸ªå½“æˆbaseline.


ICML 2023: XTab: Cross-table Pretraining for Tabular Transformers
- [XTabä»£ç ](https://github.com/BingzhaoZhu/XTab)è¿è¡Œè¦æ±‚éå¸¸è‹›åˆ», åªèƒ½åœ¨AWSä¸Šè·‘(åªæä¾›é¢„è®­ç»ƒäº†çš„æ¨¡å‹çš„AWS EC2å®ä¾‹)
- XTabæ˜¯ ç”¨äºè¡¨æ ¼transformerçš„è·¨è¡¨é¢„è®­ç»ƒçš„é€šç”¨æ¡†æ¶(a general framework for cross-table pretraining of tabular transformers)
- æ€§èƒ½ä¸å¦‚2018å¹´çš„CatBoost, ä¸”å®éªŒå½“ä¸­CatBoostæ¯”XGBoost<u>ç¨å¾®</u>å¥½ä¸€ç‚¹.
- ç›¸å…³å·¥ä½œé‡Œé¢æŠŠTabPFNä¹Ÿæ”¾åœ¨è·¨è¡¨è¿ç§»å­¦ä¹ éƒ¨åˆ†äº†
- è®¤ä¸ºä¹‹å‰çš„æ¨¡å‹æ˜¯domain-specificçš„, å› ä¸ºå®ƒä»¬æ˜¯åœ¨å„ä¸ªå•ç‹¬çš„è¡¨æ ¼é¢„æµ‹ä»»åŠ¡çš„è®­ç»ƒé›†ä¸Šé¢„è®­ç»ƒçš„
- è¯´TransTabè·¨é¢†åŸŸèƒ½åŠ›æœ‰é™, è€ŒXTabæ¯”è¾ƒæ“…é•¿. å®éªŒ(è·¨é¢†åŸŸ)é‡Œé¢Transtabä¹Ÿæ˜¯è¡¨ç°æœ€å·®.
![](assets/Pasted%20image%2020250413195013.png)
- é€šè¿‡å…±äº«transformeréª¨å¹²æ¥æ³›åŒ–è·¨æ•°æ®é›†ä¿¡æ¯
![](assets/Pasted%20image%2020250406182636.png)
- XTabè¢«åº”ç”¨äºpreviously unseen tables, å³ä¸å¯¹é¢†åŸŸå’Œåˆ—ååšä»»ä½•å‡è®¾.
- ä¾ç„¶åŸºäºFT-Transformerç­‰.
- ä¸å…¼å®¹é›¶æ ·æœ¬å­¦ä¹ , å› ä¸ºéœ€è¦è¶³å¤Ÿçš„å¾®è°ƒæ•°æ®æ¥ä»å¤´è®­ç»ƒç‰¹å¾åŒ–å™¨å’ŒæŠ•å½±å¤´.

ICLR 2023: Transfer Learning with Deep Tabular Models
- æ¢ç´¢å·²æœ‰è¡¨æ ¼æ¨¡å‹(åŒ…æ‹¬æ·±åº¦å­¦ä¹ çš„)åœ¨**è¿ç§»å­¦ä¹ **ä¸Šçš„ä¼˜åŒ–ä¸æ€§èƒ½æ½œåŠ›.
- 2022çš„ Deep neural networks and tabular data: A survey è®¤ä¸º, å¦‚ä½•çŸ¥è¯†è¿ç§»å’Œåˆ©ç”¨ä¸Šæ¸¸æ•°æ®ä¾ç„¶æ˜¯æœªè§£å†³çš„é—®é¢˜.
- è®¤ä¸ºæ·±åº¦å­¦ä¹ (å¤§æ¨¡å‹)åœ¨å°‘æ ·æœ¬çš„æ—¶å€™å ä¼˜åŠ¿.
- å®éªŒæ˜¯, æ‹¿å¸¸è§ç–¾ç—…çš„æ•°æ®, è¿ç§»é¢„æµ‹ç½•è§ç—….
- å¯ä»¥å‘ç°, é¢„è®­ç»ƒå’Œå¾®è°ƒä½¿ç”¨çš„ç‰¹å¾æ˜¯ä¸€æ ·çš„, åªæ˜¯ç›®æ ‡labelä¸ä¸€æ ·(è¿™ä¸€ç‚¹åº”è¯¥ä¸ç¬¦åˆè½¯ä»¶ç¼ºé™·çš„åœºæ™¯):
![](assets/Pasted%20image%2020250406132312.png)
- è®¤ä¸ºæ·±åº¦å­¦ä¹ (å¤§æ¨¡å‹)çš„çŸ¥è¯†è¿ç§»èƒ½åŠ›æ¯”XGBoostå’ŒCatBoostéƒ½å¼º. ä¸‹å›¾çºµè½´çš„æ ·æœ¬æ•°æ˜¯ç”¨æ¥å¾®è°ƒçš„æ ·æœ¬æ•°, è¿™ä¸ªæ ·æœ¬å¿…é¡»å’Œè¦é¢„æµ‹çš„æ ·æœ¬æ˜¯åŒä¸€ä¸ªåˆ†å¸ƒçš„.
![](assets/Pasted%20image%2020250406130250.png)


# 2025.4.22

posterior predictive distribution (PPD)

ICLR 2022: Transformers Can Do Bayesian Inference
- build models that approximate posteriors with flexible and replaceable priors using deep learning models

å‡å®šä¸€ä¸ªè¡¨æ ¼æœä»ä¸€ä¸ªåˆ†å¸ƒï¼ˆå…ˆéªŒåˆ†å¸ƒï¼‰$p$ï¼Œè€Œæ¨¡å‹æœä»è¿‘ä¼¼åˆ†å¸ƒ$q_\theta$ã€‚

ä¼˜åŒ–å…ˆéªŒæ•°æ®çš„è´Ÿå¯¹æ•°ä¼¼ç„¶å‡½æ•° (Prior-Data NLL)ç­‰ä»·äºä¼˜åŒ–è¿‘ä¼¼åˆ†å¸ƒå’Œå…ˆéªŒåˆ†å¸ƒä¹‹é—´çš„äº¤å‰ç†µï¼ˆå³è®©è¿™ä¸¤ä¸ªåˆ†å¸ƒé€¼è¿‘ï¼‰ï¼Œè€ŒPrior-Data NLLåˆç­‰äºä¸¤ä¸ªåˆ†å¸ƒä¹‹é—´çš„KLæ•£åº¦çš„æœŸæœ›+å¸¸æ•°ã€‚











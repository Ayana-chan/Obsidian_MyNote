
# KSETE


步骤 (1~3重复多次):
1. 两数据集的样本进行**抽样**(使得抽出的两个数据集的样本数量相同).
2. 结合所抽样的所有数据, **映射**(用核谱嵌入)出新的"源数据"和"目标数据".
3. 对新数据进行**普通逻辑回归**来分类, 得到预测结果.
4. **综合**每次抽样的预测结果, 得到最终预测结果.

由于映射过程需要同时结合源数据和目标数据, 因此**异构**信息是在*映射*当中得到处理的, 而后面的*逻辑回归学习*就**不考虑异构问题**了.

但是, 现在的情况是, *度量元使用同一个软件提取*, 也就是说**特征都是完全一样的**, 只不过**数据的分布不同**. KSETE虽然也能处理数据分布差别, 但它也能处理特征的不同, 能力范围超过了需求. 换句话说, 目前的需求不在KSETE的论域内.

目前的需求情况:
- 特征一样, 任务一样, **数据分布不一样**.
- 无论是*不同的项目*之间, 还是*项目的两个版本*之间, 都有数据分布的不同. 例如, 一个软件的<u>新版本</u>修复了若干bug, 那么<u>相较于旧版本</u>来说, $度量元 \rightarrow 有无bug$ 的<u>映射情况就会发生改变</u>(即使代码基本没改).

直接简单的**微调**(即拿源数据训练一个模型, 然后塞入少量新数据进行微调训练), 则需要少量的*带label的目标数据*, 或者说*目标项目的部分bug信息*. 另外, 这也应该要求较大的源数据规模. 
- 好处是能利用开源数据集;
- 坏处是要求提供目标项目<u>部分模块</u>的一定数量的bug信息.
- 跨模块也有数据分布不一致的问题?

TODO: 对于bug数据集来说, 相比于出现误标, 其出现**漏标**的可能性更大, 以至于甚至让其自己预测自己都可能可以整出点儿意义来. 另外, 反正微调都要求要用目标数据了, 那么在数据量足够的情况下是不是能干脆弄成自己预测自己. 如何消解漏标带来的影响? 是否有自己预测自己的研究? 另外标注的时候, 有些东西都不知道能不能视为bug, 而开源数据集的论文里面直接忽略了这些东西(包括难以定位的bug).
- 不完全标注??


# 3.18

KSETE的一个Baseline, 2018: Heterogeneous Defect Prediction
- 通过分析训练集, 选取出重要级别前15%的特征
- 分析训练集和目标集的特征相关性, 进行特征间的联合匹配.
- 匹配完成之后, 就是简单的同构数据集预测, 直接使用常见分类器.

---

**Tabular Data (表格数据)** 

2022: Why do tree-based models still outperform deep learning on tabular data?
- 可见那时候不如直接XGBoost等基于树的模型 (注: XGBoost是2016年的论文).
![](assets/Pasted%20image%2020250317222553.png)

2022: Revisiting Deep Learning Models for Tabular Data (FT-transformer)
- 使用了Feature Tokenizer 来把表格数据变成token. 一个特征的所有数据组成了一个token; 或者说, 一个样本的所有特征散落在各个token里面.
- 基于Transformer.
- 被指明不如XGBoost等基于树的模型.
![](assets/Pasted%20image%2020250317222533.png)

2024: From Supervised to Generative: A Novel Paradigm for Tabular Deep Learning with Large Language Models (TabFM)
- 这是一个用于<u>跨领域数据集</u>的工作.
- 对表格数据的每个样本(每一行), 都生成一句话: 数据背景 + 每个特征的意思和值 + 最终结果的意思和值.
- 使用GTL(Generative Tabular Learning)机制, 把LLM转变成TabFM(Tabular Foundation Models). 论文实验用的是llama2.
- 比GPT4差一点但接近.
![](assets/Pasted%20image%2020250317232413.png)

---

2022: Within-Project Defect Prediction of Infrastructure-as-Code Using Product and Process Metrics
- 针对的是脚本文件.
- 对度量元, 使用 决策树、逻辑回归、朴素贝叶斯、随机森林和支持向量机 进行预测, 发现随机森林最好.

2020: Deep Semantic Feature Learning for Software Defect Prediction
- 文件级或基于变更(commit).
- 基于语法树提取数据.
- 使用DBN预测.

---

TODO: XGBoost和随机森林的泛化性问题.

TODO: 2024(IEEE Access): Tabular Data Classification and Regression: XGBoost or Deep Learning With Retrieval-Augmented Generation
- 结果表明，具有RAG成分的TabR在分类方面优于XGBoost，有效地管理了不确定性。然而，在回归任务中，XGBoost继续优于TabR。

TODO: 2024: LLM2Vec: Transforming Tabular Data to Vector Space with Large Language Models

TODO 2025(普通综述文章): Deep Learning within Tabular Data: Foundations, Challenges, Advances and Future Directions


# 3.25

SIGIR 2024: Large Language Models for Tabular Data: Progresses and Future Directions
- 数据库那种关系明确的表(可以被sql和pandas操作的, 甚至有外键的)叫做结构化表(structured tables); word文档和latex出现的表是semi-structured tables; 图片(RGB矩阵)则是image tables.
- TODO refs

Trans. Mach. Learn. Res. 2024: Large Language Models (LLMs) on Tabular Data: Prediction, Generation, and Understanding - A Survey
- 表格数据，通常称为结构化数据，是指组织成行和列的数据，其中每列代表一个特定特征。
- TODO

KDD 2024: From Supervised to Generative: A Novel Paradigm for Tabular Deep Learning with Large Language Models (TabFM)
- 这是一个强调了<u>跨领域数据集</u>的工作. 其introduction里面都没提到其他跨领域数据集的任务. 应该是为了避免应用时中为单一领域而重新训练.
- TODO: 如果模型开源的话说不定能直接拿来用.
- 对表格数据的每个样本(每一行), 都生成一句话: 数据背景 + 每个特征的意思和值 + 最终结果的意思和值.
- 使用GTL(Generative Tabular Learning)机制, 把LLM转变成TabFM(Tabular Foundation Models). 论文实验用的是llama2.
- 比GPT4差一点但接近.
- 测试的时候, 使用GPT4生成任务背景和特征信息的文本.
- 同领域数据集预测称作in-domain transfer, 否则为in-domain transfer. 同领域指的是测试集里面存在于训练集有领域重合的数据.
![](assets/Pasted%20image%2020250325130510.png)

AISTATS 2023 (CCF C): TabLLM: Few-shot Classification of Tabular Data with Large Language Models
- 表格数据缺乏局部性，包含混合数据类型，列的数量通常与文本或图像数据中的特征数量相比相当小。
- 相关工作部分的机器学习部分中, 在22年认为树模型更优的论文发表之后, 作者只认可TabPFN(2022)超过了树模型.
- 工作重点在于**序列化**. TabLLM概念与具体LLM和微调方法无关, 论文的LLM使用11b的T0 encoder-decoder model (HuggingFace implementation) (理由: It was trained on a large variety of task-specific prompts); 微调方法使用T-Few(使用了k个少量标记数据); prompt使用PromptSource framework.
- 最佳的序列化方式是 **Text Template**: An textual enumeration of all features as “The column name is value.” 不过列名需要被修改成可以直接理解其含义的词, 例如`hours_per_week`甚至`hours` 需要被改成 `work hours per week`.
![](assets/Pasted%20image%2020250325121404.png)
- Text Template示例:
![](assets/Pasted%20image%2020250325124943.png)
- "We used 20% of the data as a test set" 实验应该是在同一个数据集里面, 一部分预测另一部分.
- 只有少样本下占优势:
![](assets/Pasted%20image%2020250325121719.png)
![](assets/Pasted%20image%2020250325124333.png)
- 结论: 直接使用完全没微调过的或简单微调的普通LLM, 也能发挥足够好的性能, 只要输入是text template这样的简单形式. 应该是模型直接尝试对列名进行理解和思考.


# 4.1

KDD 2024: From Supervised to Generative: A Novel Paradigm for Tabular Deep Learning with Large Language Models (TabFM)
- 论文pdf和官网叫做Towards Foundation Models for Learning on Tabular Data.
- [微软亚洲研究院官网](https://www.microsoft.com/en-us/research/publication/towards-foundation-models-for-learning-on-tabular-data/)
- Data and code will be open sourced. 目前应该尚未开源.

Trans. Mach. Learn. Res. 2024: Large Language Models (LLMs) on Tabular Data: Prediction, Generation, and Understanding - A Survey
- 表格数据，通常称为结构化数据，是指组织成行和列的数据，其中每列代表一个特定特征。
- 使用LLM进行表格序列化不太行的关键原因是, 会有幻觉, 生成不正确的东西.
- 多个工作表明, 序列化最好就是"column name is value".
- 把LLM的输出映射到想要的输出标签的过程称作target augmentation(目标增强)(下表为各个方法例子). 为了计算好一些指标(AUCROC或AUCPR)等, 可能有个需求是要求输出不是0-1而是概率, Verbalizer可以做到, 极复杂的UniPredict也行.
![](assets/Pasted%20image%2020250329200113.png)
- 医学数据包含了与时间推移变化的东西, 变量间高度关联(包括缺失), 还有笔记等非结构化数据, 因此LLM直接比树占优.

Corr abs 2023 <u>还没发</u>: Towards better serialization of tabular data for few-shot classification with large language models

NeurIPS 2022: Lift: Language-interfaced fine-tuning for non-language machine learning tasks.
- 开源
- Language-Interfaced Fine-Tuning (LIFT)
- 目的是: 在完全不改变架构或损失函数的情况下, 使用微调让LLM适应非语言任务. 测试中包含了tabular data, 包含了分类和回归.
- 提到了它的优点是可以使用原始数据, 不需要像一些基线模型一样需要特征缩放和归一化.
- 数据序列化:
![](assets/Pasted%20image%2020250329221933.png)
- 分类任务: 在类别数较高时, 性能变差. 不过目前的缺陷预测需求的类别数仅为2. 但是, 类别数低时, 也只是与基线模型**相当**. 高维(feature数较高)时性能也能保持.
![](assets/Pasted%20image%2020250329221602.png)
- 不过, 在表格数据上, 和其他大模型比起来, 可以说是最好:
![](assets/Pasted%20image%2020250329222846.png)
- 回归任务: 在低纬的时候性能就不行, 高维的时候直接说是"无效".
- 目前看来, 起码就输入来说, TabLLM已经比这LIFT优秀了.

ICML 2023: XTab: Cross-table Pretraining for Tabular Transformers
- [GitHub - BingzhaoZhu/XTab](https://github.com/BingzhaoZhu/XTab)
- 和TabPFN同一时间, 声称自己的推理复杂度与表大小无关, 所以比TabPFN更适合大表. 但是<u>没和TabPFN比</u>.
- 强调了cross-table(跨表), 并且强调自己能跨领域.
- 实验中, CatBoost一直最强.

ICLR 2023: Transfer Learning with Deep Tabular Models
- TODO

ICLR 2023: TabPFN: A transformer that solves small tabular classification problems in a second
- [GitHub - PriorLabs/TabPFN: ⚡ TabPFN: Foundation Model for Tabular Data ⚡](https://github.com/PriorLabs/TabPFN)
- 在TabLLM论文的测试里面表现最好, 在GTL论文的测试里面也足够优秀(感觉是除GTL本身和GPT4外最好的).
![](assets/Pasted%20image%2020250325121719.png)
- Prior-Data Fitted Network (PFN)
- 强调速度. 不支持零样本. TODO


















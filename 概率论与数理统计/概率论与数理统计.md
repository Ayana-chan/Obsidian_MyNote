
# 概率论概念

## 基本概念

- **总体**：所研究对象的全体
- **个体**：组成总体的每个基本单位
- **随机变量**：个体的某一项或几项指标

对总体的研究可以归结为对表征总体中个体的指标的随机变量的研究，因此可以直接说”总体$X$“是随机变量。它有分布函数$F(x)$，因此可以说“总体$F(x)$”或“正态总体”等。

- 在总体里挑出n个个体，就是**抽样**，得到的个体是**样本**。
- n称为**样本容量**。

- 在相同条件下对总体$X$进行n次重复独立观察，得到$X_1, X_2, \dots, X_n$，称为n次**简单随机抽样**（简称简单抽样）。
- 任意$X_i$都是和总体$X$有**相同分布**的<u>随机变量</u>，且**互相独立**。称随机变量$X_1, X_2, \dots, X_n$是来自总体$X$的**简单随机样本**（简称样本）。

- 抽样观察的结果是具体的数值$x_1, x_2, \dots, x_n$，称作样本观察值
- 样本所有可能取值的全体称作**样本空间**$\chi$（或$\mathcal{S}$）。例如掷骰子的样本空间是$\chi=\{1,2,3,4,5,6\}$
- 样本观察值就是样本空间里的一个点，称作**样本点**

**事件（event）** 是一组给定样本空间的随机结果。如掷骰子中的出现5（$\{5\}$）和出现奇数（$\{1, 3, 5\}$）都是事件。如果一次随机实验结果在$\mathcal{A}$中，则说事件$\mathcal{A}$已发生。

在样本空间$\chi$中事件$\mathcal{A}$的**概率**表示为$P(\mathcal{A})$。

## 概率论公理

1. 非负性：$\forall \mathcal A, P(\mathcal{A}) > 0$
2. 规范性：$\forall \mathcal \chi, P(\chi) = 1$
3. 可列可加性：对于互斥事件（$\forall i \neq j, A_i \cap A_j = \emptyset$），有$P\left(\bigcup_{i=1}^{\infty} A_i\right) = \sum_{i=1}^{\infty} P(A_i) \quad$

## 其他概念

**联合概率（joint probability）** 是多个随机变量取指定值的概率，如$P(A=a,B=b)$。恒有$P(A = a, B=b) \leq P(A=a)$。

**条件概率（conditional probability）**：在$A=a$的条件下发生$B = b$的概率:

$$P(B=b \mid A=a) = \frac{P(A=a, B=b)}{P(A=a)}$$

> [!note]
> 对于不独立的随机变量$A$和$B$，想要拆解联合概率密度$P(A, B)$，只能拆成$P(A)P(B|A)$或$P(B)P(A|B)$。

> [!note]
> $$P(A, B, C) = P(A) P(B | A) P(C | A, B)$$

**贝叶斯定理（Bayes’ theorem）**：

$$P(A \mid B) = \frac{P(B \mid A) P(A)}{P(B)}$$

**求和法则（sum rule）** 或**边际化（marginalization）**：

$$P(B) = \sum_{A} P(A, B)$$

边际化结果的概率或分布称为**边际概率（marginal probability）** 或**边际分布（marginal distribution）**。

**独立（independence）** 表示为$A \perp B$，此时$P(A \mid B) = P(A)$，即$P(A, B) = P(A)P(B)$。非独立的随机变量称作**依赖（dependence）**。

随机变量$A$和 $B$ 在给定另一个随机变量$C$时**条件独立（conditionally independent）** 表示为$A \perp B \mid C$， 此时$P(A, B \mid C) = P(A \mid C)P(B \mid C)$。

> [!notice]
> 独立和条件独立之间**没有蕴含关系**！因为C可能与A、B都有依赖，在C下原本独立的A和B之间可能也会发生依赖。

## 期望

随机变量$X$的**期望（expectation）** 或**均值（average）** 表示为：

$$E(X) = \sum_{x} x P(X = x)$$
随机变量函数$f(x)$的期望可以这样计算：

$$E_{x \sim P}(f(x)) = \sum_x f(x) P(x)$$

## 方差

随机变量$X$的**方差（variance）** 表示为：

$$\mathrm{Var}(X) = E\left((X - E(X))^2\right) =
E(X^2) - E(X)^2$$

方差的平方根被称为**标准差（standard deviation）**。

随机变量函数$f(x)$的方差为：

$$\mathrm{Var}(f(x)) = E\left(\left(f(x) - E(f(x))\right)^2\right)$$

# 数理统计


总体$X$（分布函数为$F(x)$)的样本（独立同分布）的联合分布函数为：

$$F(x_1, x_2, \dots, x_n)$$

# 注意点
## 带统计量的联合分布列与条件分布列

假设$X_1, ..., X_n$的**联合分布列**为：

$$P\{ X_1 = x_1, \cdots, X_n = x_n \} = 10 \sum_{i=1}^n{x_i}$$

则求附加了统计量$T = \sum_{i=1}^n{x_i} = t$时的分布列时，可以**直接代入**：

$$P\{ X_1 = x_1, \cdots, X_n = x_n, \sum_{i=1}^n{x_i} = t \} = 10t$$

因为联合分布列本来就是求一个完全具体的情况的概率，只受随机变量影响。t的加入不会引入额外的随机变量，只会影响$X_1, ..., X_n$的取值情况；而$X_1, ..., X_n$的任意取值的概率都只会被表示成$10 \sum_{i=1}^n{x_i}$，因此t可以直接代入。

若想求$T = \sum_{i=1}^n{x_i} = t$下的**条件分布列**，则简单进行除法即可：

$$P\{ X_1 = x_1, \cdots, X_n = x_n | t \} = \frac{P\{ X_1 = x_1, \cdots, X_n = x_n, \sum_{i=1}^n{x_i} = t \}}{P\{ \sum_{i=1}^n{x_i} = t \}}$$

而$P\{ \sum_{i=1}^n{x_i} = t \}$就要把$t$考虑成随机变量了，表示任意的$X$取值下其和刚好等于$t$的概率，因此要使用具体的$X$的分布列来计算$t$的分布列。


























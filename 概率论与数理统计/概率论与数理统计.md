
# 概率论概念

## 基本概念

- **总体**：所研究对象的全体
- **个体**：组成总体的每个基本单位
- **随机变量**：个体的某一项或几项指标

对总体的研究可以归结为对表征总体中个体的指标的随机变量的研究，因此可以直接说”总体$X$“是随机变量。它有分布函数$F(x)$，因此可以说“总体$F(x)$”或“正态总体”等。

- 在总体里挑出n个个体，就是**抽样**，得到的个体是**样本**。
- n称为**样本容量**。

- 在相同条件下对总体$X$进行n次重复独立观察，得到$X_1, X_2, \dots, X_n$，称为n次**简单随机抽样**（简称简单抽样）。
- 任意$X_i$都是和总体$X$有**相同分布**的<u>随机变量</u>，且**互相独立**。称随机变量$X_1, X_2, \dots, X_n$是来自总体$X$的**简单随机样本**（简称样本）。

- 抽样观察的结果是具体的数值$x_1, x_2, \dots, x_n$，称作样本观察值
- 样本所有可能取值的全体称作**样本空间**$\chi$（或$\mathcal{S}$）。例如掷骰子的样本空间是$\chi=\{1,2,3,4,5,6\}$
- 样本观察值就是样本空间里的一个点，称作**样本点**

**事件（event）** 是一组给定样本空间的随机结果。如掷骰子中的出现5（$\{5\}$）和出现奇数（$\{1, 3, 5\}$）都是事件。如果一次随机实验结果在$\mathcal{A}$中，则说事件$\mathcal{A}$已发生。

在样本空间$\chi$中事件$\mathcal{A}$的**概率**表示为$P(\mathcal{A})$。

**概率密度函数（Probability Density Function, PDF）**。

## 概率论公理

1. 非负性：$\forall \mathcal A, P(\mathcal{A}) > 0$
2. 规范性：$\forall \mathcal \chi, P(\chi) = 1$
3. 可列可加性：对于互斥事件（$\forall i \neq j, A_i \cap A_j = \emptyset$），有$P\left(\bigcup_{i=1}^{\infty} A_i\right) = \sum_{i=1}^{\infty} P(A_i) \quad$

## 其他概念

**联合概率（joint probability）** 是多个随机变量取指定值的概率，如$P(A=a,B=b)$。恒有$P(A = a, B=b) \leq P(A=a)$。

**条件概率（conditional probability）**：在$A=a$的条件下发生$B = b$的概率:

$$P(B=b \mid A=a) = \frac{P(A=a, B=b)}{P(A=a)}$$

> [!note]
> 对于不独立的随机变量$A$和$B$，想要拆解联合概率密度$P(A, B)$，只能拆成$P(A)P(B|A)$或$P(B)P(A|B)$。

> [!note]
> $$P(A, B, C) = P(A) P(B | A) P(C | A, B)$$

**贝叶斯定理（Bayes’ theorem）**：

$$P(A \mid B) = \frac{P(B \mid A) P(A)}{P(B)}$$

**求和法则（sum rule）** 或**边际化（marginalization）**：

$$P(B) = \sum_{A} P(A, B)$$

边际化结果的概率或分布称为**边际概率（marginal probability）** 或**边际分布（marginal distribution）**。

**独立（independence）** 表示为$A \perp B$，此时$P(A \mid B) = P(A)$，即$P(A, B) = P(A)P(B)$。非独立的随机变量称作**依赖（dependence）**。

随机变量$A$和$B$在给定另一个随机变量$C$时**条件独立（conditionally independent）** 表示为$A \perp B \mid C$， 此时$P(A, B \mid C) = P(A \mid C)P(B \mid C)$。

> [!notice]
> 独立和条件独立之间**没有蕴含关系**！因为C可能与A、B都有依赖，在C下原本独立的A和B之间可能也会发生依赖。

## 期望

随机变量$X$的**期望（expectation）** 或**均值（average）** 表示为：

$$\mu = E(X) = \sum_{x} x P(X = x)$$
随机变量函数$f(x)$的期望可以这样计算：

$$E_{x \sim P}(f(x)) = \sum_x f(x) P(x)$$

## 方差

随机变量$X$的**方差（variance）** 表示为：

$$\mathrm{Var}(X) = E\left((X - E(X))^2\right) =
E(X^2) - E(X)^2$$

方差的平方根被称为**标准差（standard deviation）**。

随机变量函数$f(x)$的方差为：

$$\mathrm{Var}(f(x)) = E\left(\left(f(x) - E(f(x))\right)^2\right)$$

## 矩

n阶**矩（moment）** 被定义为一变量的n次方与其概率密度函数之积的积分：

$$v_{n}=E(X^k)
=\int x^{n}d\left(F(x)\right)
=\int x^{n}f(x)dx$$

离散情况下可以写成：
$$v_{n}=\sum x^{n}P\left(x\right)$$

1阶矩为数学期望。


n阶**中心矩（central moment）** 要让随机变量减去均值后进行积分：

$$\mu_k=\operatorname{E}((X-\operatorname{E}(X))^k)
=\int_{-\infty}^{+\infty}(x-\mu)^kd\left(F(x)\right)
=\int_{-\infty}^{+\infty}(x-\mu)^kf(x)dx$$

0阶中心矩恒为1，1阶恒为0，二阶为方差。
# 数理统计

## 基本概念

称决定总体分布的参数为**总体参数**（往往是有已知的分布函数类型，然后只有若干参数未知）。

总体参数所属的范围称作**参数空间**$\Theta$。对应的总体分布范围$\{P_\theta:\theta \in \Theta\}$（多种分布组成的集合）称为**总体分布族**，也称为**参数分布族**。

常见的参数分布族：
- Poisson分布族：$\{P(\lambda):\lambda > 0\}$
- 正态分布族：$\{N(\mu, \sigma^2): \mu \in \mathbb{R}, \sigma^2 > 0\}$
- 0-1（或两点）分布族：$\{B(1, p): 0 < p < 1\}$

> [!note]
> 总体$X$（分布函数为$F(x)$)的样本（独立同分布）的联合分布函数为：
> $$F(x_1, x_2, \dots, x_n) = \prod_{i=1}^n{x_i}$$

## 大数定律

**切比雪夫大数定律**：

$$\lim_{n\to\infty}P\{ |\frac{1}{n}\sum_{k=1}^{n}x_{k}-\frac{1}{n}\sum_{k=1}^{n}Ex_{k}|<\varepsilon \}=1$$

> [!tip]
> $Ex_{k}$也可以表示成$\mu_k$。

若各样本独立同分布，则有**辛钦大数定理**：
$$\lim_{n\to\infty}P\Big\{ \left| \frac{1}{n}\sum_{i=1}^{n}X_{i}-\mu \right|<\varepsilon\Big\}=1$$

**伯努利（Bernoulli）大数定律**：设$n_{\mathcal{A}}$是n次独立试验中事件$\mathcal{A}$发生的次数，且事件$\mathcal{A}$在每次试验中发生的概率为p，则对任意正数$\epsilon$，有：

$$\lim_{n\to\infty}P(\left|\frac{n_{\mathcal{A}}}{n}-p\right|<\varepsilon)=1$$



### 推论

样本的**k阶中心矩**依概率收敛于总体的k阶中心矩，即
$$B_k\stackrel{P}{\longrightarrow}\nu_k\quad n\rightarrow+\infty,k=1,2,\cdots,m$$

## 统计量

若样本的函数$T(X_1, X_2, \dots, X_n)$不含任何未知参数，则称该函数为**统计量**。

几个常见统计量：
- 样本均值：$\overline{X}=\frac{1}{n}\sum_{i=1}^{n}X_{i}$
- 样本方差（均方差）（无偏）：$S^{2}=\frac{1}{n-1}\sum_{i=1}^{n}(X_{i}-\overline{X})^{2}$
- 样本k阶原点矩：$A_{k}=\frac{1}{n}\sum_{i=1}^{n}X_{i}^{k}\left(k=1,2,\cdots,\right)$
- 样本k阶中心矩：$B_{k}=\frac{1}{n}\sum_{i=1}^{n}(X_{i}-\overline{X})^{k}\left(k=1,2,\cdots,\right)$

样本二阶原点矩可以表示为$\hat{\sigma}^{2}=\frac{1}{n}\sum_{i=1}^{n}\left(X_{i}-\overline{X}\right)^{2}$。

**顺序统计量**$X_{(k)}$表示样本中第k小的那个样本。显然，它是$X_1, X_2, \dots, X_n$的函数，且不含未知参数，是一个合法的统计量。
[概率论与数理统计](概率论与数理统计/概率论与数理统计.md#^l9p7tp)
特殊的，有：
$$X_{\left(1\right)}=\min\left\{X_{1},X_{2},\cdots,X_{n}\right\}$$
$$X_{(n)}=\max\{X_{1},X_{2},\cdots,X_{n}\}$$

若总体$X$的分布函数为$F(x)$，则：

$$F_{X_{\left(1\right)}}\left(t\right)=1-\left[1-F\left(t\right)\right]^{n}$$
$$F_{X_{\left(n\right)}}\left(t\right)=F^{n}\left(t\right)$$
**样本极差**：

$$R=X_{\left(n\right)}-X_{\left(1\right)}$$

**样本中位数**：

$$
m_{0.5}=\begin{cases}X_{\left(\frac{n+1}{2}\right)},&n\text{是奇数}\\
\frac{1}{2}\left(X_{\left(\frac{n}{2}\right)}+X_{\left(\frac{n}{2}+1\right)}\right),&n\text{是偶数}\end{cases}
$$

## 充分统计量

设样本总体分布族为$\{P_{\theta}:\theta\in\Theta\}$，若给定$T(X_{1},X_{2},\cdots,X_{n})=t$时，样本$X_1, X_2, \dots, X_n$的条件分布函数$F_{\theta}\left(x_{1},x_{2},\cdots,x_{n}\mid t\right)$与参数$\theta$无关，则称统计量$T(X_1,X_2,\cdotp\cdotp\cdotp,X_n)$为参数$\theta$的**充分统计量**。定义中，“条件分布函数”可以被替换为”条件密度函数“或离散的”条件分布列“，因为它们互相一一对应，不丢失信息。

> [!tip]
> 计算条件分布函数时，需要注意[带统计量的联合分布列与条件分布列](概率论与数理统计/概率论与数理统计.md#带统计量的联合分布列与条件分布列)的计算流程。

**因子分解定理**：统计量$T(x)$是**充分统计量**，*当且仅当*：<u>联合分布列或密度函数</u>$p\left(x;\theta\right)$对所有$x \in \chi$都可以被分解成：

$$p(x;\theta)=g(T(x),\theta)h(x)$$

$g$是样本空间和参数分布族的实值函数，$h$是与参数无关的样本空间上的实值函数。

> [!notice]
> $h(x)$可以是常数。

> [!notice]
> $T(x)$函数可以是元组，如$T(x) = \left(\sum_{i=1}^{n}x_{i},\sum_{i=1}^{n}x_{i}^{2}\right)$。

> [!tip]
> 因子分解求取充分统计量的一个简单流程是：如果有$x$与$\theta$难以分离，那么就想办法把这部分$x$纳入到$T(x)$中（最暴力的就是将其塞入$T(x)$的元组中）。最“坏”的情况是全部$x$都被纳入$T(x)$，使得$h(x)$与$x$无关（变成常数函数）。

> [!note]
> 一般情况下，若$T(x)$是充分统计量，$g(t)$是一一对应的实函数(可以是向量函数), 则$g(T(x))$也是充分统计量。

## 经验分布函数

**经验频数**$v_n(x)$表示给定x，当前观察值$x_1, x_2, \dots, x_n$中不大于x的个数。这是一个随机变量。经验频数的<u>概率</u>为分布函数在x上的取值$F(x) = P(X \leq x)$。

$v_n(x)$实际上是进行了一次n重Bernoulli实验（每个样本都与x比大小，得到的是${X \leq x}$事件的出现次数），因此$v_n(x)$服从二项分布$B(n,F(x))$，即：

$$
P\left\{v_{n}\left(x\right)=k\right\}
=C_{n}^{k}\left[F\left(x\right)\right]^{k}\left[1-F\left(x\right)\right]^{n-k},\quad k=0,1,2,\cdots,n
$$

将$v_n(x)$代入[Bernoulli大数定律](概率论与数理统计/概率论与数理统计.md#大数定律)，可知：

$$\lim_{n\to+\infty}P\left\{\left|\frac{v_{n}\left(x\right)}{n}-F\left(x\right)\right|\geqslant\varepsilon\right\}=0$$

因此可知：

$$\frac{v_n(x)}{n} \stackrel{P}{\longrightarrow} F(x)$$

> [!tip]
> 虽然$v_n(x)$确实对每个样本都进行了独立的检测，但只是简单的比大小，而样本本身就可以从小到大排列。因此，总是有一部分较小的样本全部检测失败，而剩下的全部成功。

由此，可以定义**经验分布函数**：

$$
F_{n}(x)=\frac{v_{n}(x)}{n}=\begin{cases}0,&x<x_{(1)}\\
\frac{k}{n},&x_{(k)}\leqslant x<x_{(k+1)},&k=1,2,\cdots,n-1\\
1,&x\geqslant x_{(n)}\end{cases}
$$

> [!note]
> 相对地，$F(x)$就被称作**理论分布函数**。

经验分布函数是<u>顺序统计量的函数</u>。

经验分布函数单调不减，右连续，值域$I \in [0,1]$，是关于$x$的阶梯函数。

显然，其数学期望：

$$E(F_{n}(x))=E\left(\frac{v_{n}(x)}{n}\right)=F(x)$$

**Glivenko定理**：当$n \rightarrow \infty$时，经验分布函数以概率1关于$x$**一致收敛**于理论分布函数。即：

$$P\left\{\lim_{n\to\infty}\sup_{-\infty<x<\infty}\left|F_{n}\left(x\right)-F\left(x\right)\right|=0\right\}=1$$

可以利用经验分布函数，让样本矩的观察值使用积分来表示（阶梯函数的积分依然是离散的）：

$$
\begin{gathered}
\overline{x}=\frac{1}{n}\sum_{i=1}^{n}x_{i}=\int_{-\infty}^{+\infty}xdF_{n}\left(x\right) \\
S^{2}=\frac{1}{n-1}\sum_{i=1}^{n}\left(x_{i}-\overline{x}\right)^{2}=\frac{n}{n-1}\frac{1}{n}\sum_{i=1}^{n}\left(x_{i}-\overline{x}\right)^{2}=\frac{n}{n-1}\int_{-\infty}^{+\infty}\left(x-\overline{x}\right)^{2}dF_{n}\left(x\right) \\
A_{k}=\frac{1}{n}\sum_{i=1}^{n}x_{i}^{k}=\int_{-\infty}^{+\infty}x^{k}dF_{n}\left(x\right),\quad k=2,3,\cdots \\
B_{k}=\frac{1}{n}\sum_{i=1}^{n}\left(x_{i}-\overline{x}\right)^{k}=\int_{-\infty}^{+\infty}\left(x-\overline{x}\right)^{k}dF_{n}\left(x\right),\quad k=2,3,\cdots 
\end{gathered}
$$

# 特殊函数

## 示性函数

在满足要求时为1，否则为0。

$$I_{A}\left(u\right)=\begin{cases}1,&u\in A\\0,&u\notin A\end{cases}$$
例如，限定区间范围的示性函数：

$$I_{\left\langle 5\leqslant t_{1}\leqslant t_{2}\leqslant 9\right\rangle}\left(t_{1},t_{2}\right)$$

# 注意点
## 带统计量的联合分布列与条件分布列

假设$X_1, ..., X_n$的**联合分布列**为：

$$P\{ X_1 = x_1, \cdots, X_n = x_n \} = 10 \sum_{i=1}^n{x_i}$$

则求附加了统计量$T = \sum_{i=1}^n{x_i} = t$时的分布列时，可以**直接代入**：

$$P\{ X_1 = x_1, \cdots, X_n = x_n, \sum_{i=1}^n{x_i} = t \} = 10t$$

因为联合分布列本来就是求一个完全具体的情况的概率，只受随机变量影响。t的加入不会引入额外的随机变量，只会影响$X_1, ..., X_n$的取值情况；而$X_1, ..., X_n$的任意取值的概率都只会被表示成$10 \sum_{i=1}^n{x_i}$，因此t可以直接代入。

若想求$T = \sum_{i=1}^n{x_i} = t$下的**条件分布列**，则简单进行除法即可：

$$P\{ X_1 = x_1, \cdots, X_n = x_n | t \} = \frac{P\{ X_1 = x_1, \cdots, X_n = x_n, \sum_{i=1}^n{x_i} = t \}}{P\{ \sum_{i=1}^n{x_i} = t \}}$$

而$P\{ \sum_{i=1}^n{x_i} = t \}$就要把$t$考虑成随机变量了，表示任意的$X$取值下其和刚好等于$t$的概率，因此要使用具体的$X$的分布列来计算$t$的分布列。

























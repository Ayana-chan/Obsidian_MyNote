
# 基本概念

[1. 引言 — 动手学深度学习 2.0.0 documentation](https://zh.d2l.ai/chapter_introduction/index.html)

## 训练

假设有一个程序，它接收**输入（input）** 后，就会得到**输出（output）**。这个程序有一些**参数（parameter）**，它们控制了程序的行为。通过适当地<u>调整参数</u>，可以让程序的<u>行为</u>更符合我们的预期。任一调整参数后的程序被称为**模型（model）**；通过操作参数而生成的所有不同程序（输入-输出映射）的集合称为“**模型族**”。

当有一个**数据集(dataset)** 后，可以将其放入程序来查看输入输出，并评估好坏，从而调整参数让其行为更好。使用数据集来选择参数的元程序被称为**学习算法（learning algorithm）**。

在机器学习中，**学习（learning）** 是一个**训练（train）** 模型的过程。 通过这个过程，我们可以发现正确的参数集，从而使模型强制执行所需的行为。 换句话说，我们**用数据训练模型**。

训练步骤：
1. 从一个随机初始化参数的模型开始，这个模型基本没有“智能”；
2. 获取一些数据样本（输入和对应的预期输出）；
3. 调整参数，使模型在这些样本中表现得更好；
4. 重复第（2）步和第（3）步，直到模型在任务中的表现令人满意。

> [!note]
> 可见，被训练的程序变成了个黑盒，无需关注其具体逻辑，也能通过自动调参来约束行为。因此，音频输入到智能回答输出可能完全不需要做语音文字识别。

不需要自己设计具体执行逻辑，而是让数据来规定程序该怎么做。这种“通过用数据集来确定程序行为”的方法可以被看作用**数据编程（programming with data）**。

## 核心组件

机器学习的核心组件：
1. 可以用来学习的**数据（data）**；
2. 如何转换数据的**模型（model）**；
3. 一个**目标函数（objective function）**，用来量化模型的有效性；
4. 调整模型参数以优化目标函数的**算法（algorithm）**。

数据集由多个**样本（example, sample）**（或者叫**数据点（data point）** 或者叫**数据实例_data instance）**）组成，这些样本大多是独立同分布的。

通常每个样本由一组称为**特征（features，或协变量（covariates））** 的属性组成。机器学习模型会根据这些属性进行预测。若样本的特征的类别和长度都相同时，说明其特征向量长度是完全一样的，这个长度被称为数据的**维数（dimensionality）**。

> [!example]
> 如果一个图片数据集，所有图片的尺寸和颜色表达方式相同，那么它们就有同等的特征向量长度，其维数为**表达所有像素数据所需的数字数**。

> [!note]
> 与传统机器学习方法相比，深度学习的一个主要优势是可以处理不同长度的数据。

> [!note]
> 深度学习与经典方法的区别主要在于：前者关注的功能强大的模型，这些模型由神经网络错综复杂的交织在一起，包含层层数据转换，因此被称为**深度学习（deep learning）**。

<u>模型的优劣程度</u>的*度量*称为**目标函数（objective function）**（由于很多情况下都是目标函数值越小越优良，因此也称为**损失函数（loss function，或cost function）**）。这种函数往往是可被优化的，即可以知道怎么调整才能让其输出更好。

> [!note]
> - 当任务在试图预测数值时，最常见的损失函数是**平方误差（squared error）**，即预测值与实际值之差的平方。 
> - 当试图解决分类问题时，最常见的目标函数是**最小化错误率**，即预测与实际情况不符的样本比例。 
> 
> 有些目标函数（如平方误差）很容易被优化，有些目标（如错误率）由于不可微性或其他复杂性难以直接优化。 在这些情况下，通常会优化**替代目标**。

可用数据集通常可以分成两部分：
- **训练数据集（training dataset，或训练集（training set））** 用于拟合模型**参数**
- **测试数据集（test dataset，或称为测试集（test set））** 用于**评估**拟合的模型

当一个模型在训练集上表现良好，但不能推广到测试集时，这个模型被称为**过拟合（overfitting）** 的。

大多流行的优化算法通常基于一种基本方法–**梯度下降（gradient descent）** 来调整参数，以降低损失。

## 各种机器学习问题

### 监督学习

**监督学习（supervised learning）** 擅长在“给定输入**特征（feature）**（或者说协变量（covariate））”的情况下预测**标签（label）**（或者说目标（target））（**特征$\rightarrow$标签**）。 每个<u>“特征-标签”对</u>都称为一个**样本（example）**。有时，即使标签是未知的，样本也可以指代输入特征。我们的目标是生成一个模型，<u>能够将任何输入特征映射到标签（即预测）</u>。

- **回归（regression）**：标签是具体的**数值**，如房子信息$\rightarrow$价格。
- **分类（classification）**：标签是**类别（category，正式称为类（class））**。给定一个样本特征，模型为每个可能的类分配一个<u>概率</u>。把分类的各类别的概率乘上该分类的收益（或风险、伤害）就能得到决策的损失函数，从而给出决策。
- **标记问题**：学习预测不相互排斥的类别的问题称为**多标签分类（multi-label classification）**。例如给文章标上多个相关的标签。
- **搜索**：要求结果集有一定的**顺序**，使得用户可以先看到最相关的东西。
- **推荐系统（recommender system）**：进行**个性化**的推荐，以达成目标（如让该用户掏钱或下载）。
- **序列学习**：如果输入之间有相关性，则需要模型对输入有记忆能力（而不能简单当做独立的因变量）。例如视频，通过对每一帧按序解析并结合分析，可以更好地预测下一帧会发生什么。


### 无监督学习

数据中<u>不含有“目标”</u>的机器学习问题通常被为**无监督学习（unsupervised learning）**。即给定数据，但不对输出有明确要求。

- **聚类（clustering）**：将数据分为若干组。
- **主成分分析（principal component analysis）**：能否找到少量的参数来准确地捕捉数据的线性相关属性，即找到能描述数据的最重要的几个方面。
- **因果关系（causality）** 和**概率图模型（probabilistic graphical models）**：找出数据的根本原因。
- **生成对抗性网络（generative adversarial networks）**：提供一种合成数据的方法。

### 与环境互动


上面的所有学习都是先获取完数据再训练，一旦开始训练就与环境不再有关联，因此称为**离线学习（offline learning）**。

如果人工智能拥有与环境互动的能力的话，那么它的行为就必然会对环境产生影响，这需要被顾虑到。这里的人工智能是“**智能代理**”，而不仅是“预测模型”。


### 强化学习

在强化学习问题中，**智能体（agent）** 在一系列的时间步骤上<u>与环境交互</u>。 在每个特定时间点，智能体从环境接收一些**观察（observation）**，并且必须选择一个**动作（action）**，然后通过某种机制（有时称为<u>执行器</u>）将其传输回环境，最后智能体从环境中获得**奖励（reward）**。 此后新一轮循环开始，智能体接收后续观察，并选择后续操作，依此类推。

![500](assets/1729072220206.png)

强化学习的目标是产生一个好的**策略（policy）**。 强化学习智能体选择的“动作”受策略控制，即一个从环境观察映射到行动的功能。

> [!note]
> 强化学习框架的通用性十分强大。 例如，我们可以**将任何监督学习问题转化为强化学习问题**。 假设我们有一个分类问题，可以创建一个强化学习智能体，每个分类对应一个“动作”。 然后，我们可以创建一个环境，该环境给予智能体的奖励。 这个奖励与原始监督学习问题的损失函数是一致的。

- 当环境可被完全观察到时，强化学习问题被称为**马尔可夫决策过程（markov decision process）**。 
- 当状态不依赖于之前的操作时，我们称该问题为**上下文赌博机（contextual bandit problem）**。 
- 当没有状态，只有一组最初未知回报的可用动作时，这个问题就是经典的**多臂赌博机（multi-armed bandit problem）**。


# 线性回归


**回归（regression）** 是能为一个或多个<u>自变量与因变量之间关系</u>建模的一类方法。

**线性回归（linear regression）**假设：
- 自变量和因变量是线性关系。允许包含噪声。
- 任何噪声都比较正常，如遵循正态分布。

对索引为$i$的样本,其输入表示为$\mathbf{x}^{(i)}=[x_1^{(i)},x_2^{(i)}]^\top$，其对应的标签是$y^{(i)}\text{。}$

$w$为**权重（weight）**，$d$为**偏置（bias）**（或offset、intercept），它们是**模型参数（model parameters）**。令$\mathbf x$为单个数据样本的特征，则预测结果$\hat y$可以表示为：
$$\hat{y} = w_1  x_1 + ... + w_d  x_d + b = \mathbf{w}^\top \mathbf{x} + b$$

使用$\mathbf{X} \in \mathbb{R}^{n \times d}$来表示整个数据集的$n$个样本，每一行是一个样本，每一列是一个特征。令特征集合$\mathbf X$的预测结果为$\mathbf{\hat y}$，于是有：
$${\hat{\mathbf{y}}} = \mathbf{X} \mathbf{w} + b$$

线性回归的目标是找到一组权重向量$\mathbf w$和偏置$b$，使得当给定从$\mathbf X$的同分布中取样的新样本特征时，这组权重向量和偏置能够使得<u>新样本预测标签的误差</u>尽可能小。

定义一个样本的平方误差：
$$l^{(i)}(\mathbf{w}, b) = \frac{1}{2} \left(\hat{y}^{(i)} - y^{(i)}\right)^2$$

则所有样本的损失均值：
$$L(\mathbf{w}, b) =\frac{1}{n}\sum_{i=1}^n l^{(i)}(\mathbf{w}, b) =\frac{1}{n} \sum_{i=1}^n \frac{1}{2}\left(\mathbf{w}^\top \mathbf{x}^{(i)} + b - y^{(i)}\right)^2$$

目标是找到$\mathbf{w}^*$和$b^*$来最小化$L$：
$$\mathbf{w}^*, b^* = \operatorname*{argmin}_{\mathbf{w}, b}\  L(\mathbf{w}, b).$$
可以用一个公式简单地表达出来的解叫作**解析解（analytical solution）**。线性回归有解析解。把$b$加入到$\mathbf w$当中，那么就只需要最小化$\|\mathbf{y} - \mathbf{X}\mathbf{w}\|^2$，通过求导就能得到解析解：
$$\mathbf{w}^* = (\mathbf X^\top \mathbf X)^{-1}\mathbf X^\top \mathbf{y}.$$


---
> [!warning]
> 还是没必要抄书了。

这些可以调整但不在训练过程中更新的参数称为**超参数（hyperparameter）**。 **调参（hyperparameter tuning）** 是选择超参数的过程。

# 多层感知机

输入为(一个样本的)所有特征, 然后仿射到隐藏层(全连接,即一个隐藏节点与所有特征相关), 之后每个隐藏节点进行一次激活函数计算(非线性计算) (隐藏节点数量是任意的), 最后再把所有隐藏节点仿射到输出层.

将模型在训练数据上拟合的比在潜在分布中更接近的现象称为**过拟合（overfitting）**， 用于对抗过拟合的技术称为**正则化（regularization）**。

- **训练误差（training error）**: 模型在训练数据集上计算得到的误差。
- **泛化误差（generalization error）**: 模型应用在同样从原始样本的分布中抽取的无限多数据样本时，模型误差的期望。一般使用一个有限的独立测试集来估计.

时间和地域等因素都会破坏**独立同分布假设（i.i.d. assumption）**, 从而损失泛化性.

可调整参数的<u>数量</u>**过大**, <u>取值范围</u>**过大**, 或者<u>训练集</u>**过小**时, 会容易过拟合.

训练误差和验证误差都很严重, 但它们之间仅有一点差距, 称为**欠拟合（underfitting）**.

过拟合不一定不好,只要验证误差小就行.

数据偏少时, 使用更简单的模型效果可能更好.

泛化性(防止过拟合)和灵活性(表达能力范围)之间的这种基本权衡被描述为**偏差-方差权衡（bias-variance tradeoff）**。

权重衰减是在输出后进行的, 因此在结果上进行求导就行(导数为$\lambda \vec w$), 在梯度下降时额外减去的值为$\eta \times \lambda \vec w$.

# 迁移学习 Transfer Learning


**迁移学习**的定义: 给定
- 源域$D_s$和学习任务$T_s$
- 目标域$D_t$和学习任务$T_t$
迁移学习的目的是 获取源域$D_s$和学习任务$T_s$中的知识 以帮助提升 目标域中的预测函数$f_t(\cdot)$的学习. 其中$D_s\neq D_t$或者$T_{s}\neq T_{t}$.

- 基于**实例** Instanced-based deep transfer learning: 在source domain中挑选符合target domain约束空间的数据, 然后和target domain中的数据一起训练. 和Adaboost算法联合使用更佳.
- 基于**映射** Mapping-based deep transfer learning: target domain 和 source domain 具有不同的<u>分布</u>, 将实例从源域和目标域映射到<u>新的数据空间</u>。
- 基于**网络** Network-based deep transfer learning: 将原领域中预先训练好的部分网络, 包括其网络结构和连接参数, 重新利用, 将其转化为用于目标领域的深度神经网络的一部分.
- 基于**对抗** Adversarial-based deep transfer learning: 在生成对抗性网络(GAN)的启发下, 引入对抗性技术, 寻找既适用于源域又适用于目标域的可迁移表达. 它基于这样的假设: "为了有效的迁移，良好的表征应该是对主要学习任务的区别性，以及对源域和目标域的不加区分."


# 微调

- **数据量少, 但数据相似度非常高**: 在这种情况下，我们所做的只是修改*最后几层*或最终的softmax图层的*输出类别*。
- **数据量少, 数据相似度低**: 在这种情况下，我们可以*冻结*预训练模型的初始层（比如$k$层），并再次训练剩余的$n-k$层。由于新数据集的相似度较低，因此根据新数据集对较高层进行重新训练具有重要意义。
- **数据量大, 数据相似度低**: 在这种情况下，由于我们有一个大的数据集，我们的神经网络训练将会很有效。但是，由于我们的数据与用于训练我们的预训练模型的数据相比有很大不同。使用预训练模型进行的预测不会有效。因此，最好根据你的数据*从头开始训练神经网络(Training from scatch)*。
- **数据量大, 数据相似度高**: 这是理想情况。在这种情况下，预训练模型应该是最有效的。使用模型的最好方法是保留模型的体系结构和模型的初始权重。然后，我们可以使用在预先训练的模型中的*权重*来*重新训练*该模型。




# 类不平衡

数据集的标签可能较为集中, 导致即类不平衡.

## SMOTE

SMOTE算法 背后的主要思想是通过生成合成样本来弥合少数群体和多数群体之间的差距。

1. 识别少数样本：第一步涉及识别数据集中属于少数类别的样本。

2. 识别K近邻：对于每个少数样本，SMOTE 识别其在特征空间中的 K-近邻。通常，欧几里德距离度量用于测量数据点之间的相似性。

3. 合成样本生成：一旦识别出邻居，SMOTE 就会选择随机邻居并计算少数样本的特征向量与其所选邻居之间的差异。然后将该差异乘以 0 到 1 之间的随机数，并将其添加到少数样本的特征向量中。此过程会创建新的合成样本，这些样本位于少数样本与其所选邻居之间的线段上. 重复生成合成样本的过程，直到达到所需的类别平衡水平。


# 生成式AI杂记

![](assets/Pasted%20image%2020250322125454.png)

生成式AI的产出内容就是AIGC (也往往用AIGC指代生成式AI).

有的生成式AI不生成<u>文本</u>, 而有的大语言模型也不适合<u>生成</u>东西(如BERT), 因此生成式AI和大语言模型概念不互为子集.

GPT = generative pre-trained transformer

RNN (循环神经网络) 在往后走时很容易忘记前面的东西.
![](assets/Pasted%20image%2020250322130915.png)

LSTM用于解决RNN的记忆问题, 但依然无法解决并行计算问题.
![](assets/Pasted%20image%2020250322131001.png)


# Transformer

![](assets/Pasted%20image%2020250322132600.png)

文本被划分为token, token被使用数字(**token id**)表示(是为了让程序更好记录). 之后传入**嵌入层**, 让每个token信息都能用**向量**表示, 向量的长度即是维度(原论文里面是512), 向量表达了token在多维坐标系中的坐标. 相似的词的嵌入向量更接近.

**位置编码(positional encoding)**: 将token的序列位置编码为向量, 与词的嵌入向量相加后输入给模型. 因为输入信息里包含位置信息, 所以所有输入可以以任意顺序给出, 从而增强并发能力.
![](assets/Pasted%20image%2020250322133256.png)

自注意力: 通过训练, 可以知道一个词与其他所有词之间的权重, 于是就能发现最关联的词.

**多头自注意力**: 词与词之间的权重是多方面的, 各个方面可以独立计算.
![](assets/Pasted%20image%2020250322133856.png)

解码器的开头的输入, 可以<u>把已经输出的文本作为输入传入</u>, 从而保持连贯. 最开始的时候, 这个输入是空的开头.

**带掩码的多头自注意力**: 在生成一个词的时候, 让模型无法看到目标词后面的序列.

N个编码器的<u>最后一个</u>的输出, 才会被接入到<u>每个</u>解码器中.
![](assets/Pasted%20image%2020250322134728.png)

解码器的最后, 使用线性层+softmax, 将解码器输出转变为词汇表的概率分布; 之后选择概率最大的作为结果.

不符合要求(不真实)的输出被称作**幻觉(hallucination)**.

![400](assets/Pasted%20image%2020250322135033.png)

变种:
- encoder-only(仅编码器) / autoencoding(自编码) model. 适合掩码语言建模(猜被遮住的词)和情感分析. 如BERT.
- decoder-only(仅解码器) / autoregressive(自回归) model. 适合文本生成. 如GPT系列.
- encoder-decoder(编码器-解码器) / sequence-to-sequence(序列到序列) 模型. 保留原样. 适合翻译, 总结等. 如T5, BERT.

# ChatGPT

- **预训练**: 使用无监督学习, 从大量文本学习出基座模型.
- **微调**: 使用被标注的高质量对话进行监督学习来微调, 数据量和成本比预训练少. 称作监督微调(Supervised Fine-Tuning, SFT).
- 额外训练**奖励模型**: 使用上面的SFT模型对一个问题生成多个回答, 然后人类手动标注排序回答的质量; 使用这些回答和其质量标注来训练奖励模型, 让其有预测<u>一个回答的评分</u>的能力.
- 使用奖励模型对SFT进行**强化学习**, 使得SFT尽力符合奖励模型的高分要求.

**提示工程(Prompt Engineering)**:
- 小样本提示: 在文本输入的前面加上多个问答示范, 让AI临时学习. 这还可以让AI以特定的形式(符合示范)生成回答.
- 思维链(Chain-of-Thought): 由于每个token的生成时间没有区别, 这就导致ai非常不擅长简单答案的数学计算. 使用思维链, 就是在示范回答里面添加计算过程, 这样ai也会模仿进行过程分解推理, 从而增强回答正确率.
- 分步骤思考: 直接在问题的末尾加上"让我们分步思考(think step by step)", 也能加强回答.

**程序辅助语言模型(Program-Aided Language Models, PAL)**: 让AI进行计算任务的时候, 不要求AI给出计算结果, 而是要求给出进行此计算所需的代码(使用思维链进行示范要求), 然后把代码跑起来, 并把结果返回给AI嵌入回答.

**知识截断**: 训练完成的模型无法知道新发生的事情. **ReAct框架** (reason + action): 行动部分会根据关键字与外界进行交互, 比如搜索引擎搜索一个关键字, 或者调用某个应用的API.
![](assets/Pasted%20image%2020250322150153.png)

# RAG

检索增强生成(Retrieval Augmented Generation)

小众细分的领域, AI回答可能不太好; 此外, 内部文件和个人数据等无法拿来训练AI, 当然也无法让AI进行有关的回答. RAG即是给AI提供一个外部知识文档.
1. 外部知识文档被划分为一个个段落. 每个段落被转为一个向量, 众向量存在向量数据库中.
2. 提问题的时候, 问题也会被转为向量.
3. 在向量数据库里面查询和问题向量最接近的段落向量, 然后将段落和问题合在一起送给AI.
4. AI会将这外部文档的段落作为上下文, 从而基于里面的信息给出回答.




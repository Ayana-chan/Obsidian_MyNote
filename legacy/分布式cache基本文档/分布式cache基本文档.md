# 需求

一个分布式的、key-value形式的cache。

可以进行GET（读取）、PUT（添加或修改）、DELETE（删除）操作。

基于http进行访问以兼容各种客户端。

一致性要求：
- 满足线性一致性。即从结果来看，所有操作总是按某一个顺序逐个进行。
- 一个key只能存储一次，且一旦存在就必须可以被访问，不能有重复或冲突。
- 因为是cache，所以数据可以在适当的时候被销毁，也即容许miss。

每个服务器都有容量上限，因此存储的数据是有限的，要在过满时销毁旧数据。

当有node服务器宕机后，要保证在失去所有node前依旧可以实现功能。

# 总体结构

使用Golang实现。

一个router服务器，多个node（节点）服务器。

目前的代码不支持动态添加node服务器，只能在启动时定死所有node。启动方式是：先开启数个node服务器，然后开启router服务器。开启router时就定死了node服务器的地址。因此，node不知道router，但router知道所有node。

外部访问的是router服务器（提供了几个API），向其发送操作请求；router接收到请求后，将其分配到特定的某个node；node被分配到请求后，将请求应用到其本地。

node的数据超过上限后，以LRU逻辑删除旧数据。无视key的占用空间，只计算value的占用空间。

如果router对node的请求失败，则认定node宕机，在router中删掉该node的信息。此时相当于该node的所有数据都被清空。
# 使用
## 启动命令

```bash
#启动节点
go run run_nodeserver.go -端口号 -LRU容量(单位：字节)
#启动router
go run run_router.go 多个节点地址（以空格分隔） -端口号 -每个真实节点对应的虚拟节点数
```

```bash
#示例
start go run run_nodeserver.go -5001 -50
start go run run_nodeserver.go -5002 -50
start go run run_nodeserver.go -5003 -50

start go run run_router.go localhost:5001 localhost:5002 localhost:5003 -5999 -5
```

## API

- GET {Router地址}/cache/{key值}  来进行查询
- POST {Router地址}/cache/{key值}  来进行设值，值通过http body发送
- DELETE {Router地址}/cache/{key值}  来进行删值

示例：

![500](assets/Pasted%20image%2020230605215042.png)

![500](assets/Pasted%20image%2020230605215116.png)

![500](assets/Pasted%20image%2020230605215134.png)


# 具体设计


## router

获取key参数，调用一致性哈希分配key到一个node，然后向该node发送一个http请求（基本相当于将请求原封不动地转发）。

### 基于一致性哈希实现key分配

#### 功能性

我们的目标：构建以key为自变量、以目标node为因变量的函数，即每个key都对应唯一一个目标node。这样的话，当我们要访问一个key时，就会固定地访问一个特定的服务器，而不会错误地访问其他服务器造成重复或冲突。

我们采用**一致性哈希**（[一致性哈希的简单认识](https://baijiahao.baidu.com/s?id=1735480432495470467&wfr=spider&for=pc)）来完成这件事。

将哈希值转为int，则任何值的哈希值都以均匀的概率分布在某个整数区间$[H\_MIN,H\_MAX]$。不妨将此区间绘制成环（**哈希环**），即在一个圆上，某一点为`H_MIN`，顺时针方向数字逐渐变大，最大为`H_MAX`，且`H_MAX`就是`H_MIN`在逆时针方向上的邻居。

对任一node，求其编号的哈希，则这些哈希会较均匀地分布在这个环上。分配key时，执行以下算法：

1. 对任一key，求其哈希为h，求哈希值比h大的所有node中哈希值最小的一个作为目标node；
2. 若h大于所有node，则将哈希值最小的node作为目标node。

其等价描述为：**对于环上的每一个点，其归属于顺时针方向上的第一个node。**

由于每个key都唯一对应环上的某个点，于是每个key都归属于一个固定的node。

#### 非功能性


- **不均匀**：每个服务器能被分配到哪些key取决于它们的哈希值分布。因此，使用中key分配的均匀程度取决于初始化情况。在极端情况下，有些服务器可能根本拿不到几个key，而有些服务器包揽了大部分请求，从而导致性能浪费。
- **雪崩**：若一个服务器发生故障被router删除，那么它管理的key范围会附加给顺时针方向上的节点。这会让该节点的访问量瞬间增加，很可能导致该节点也跟着崩溃；巨大的访问量又传递给下一个节点，又崩溃……

添加**虚拟节点**能缓解问题。假如有3个node，每个node都对应5个虚拟节点，即每个node都对应5个哈希值。当一个key被分配到某个虚拟节点时，就相当于被分配到该虚拟节点所属的node。

于是哈希环就被分为15份。每个node的5个哈希值不一定相邻，它们全都均匀分布在15个当中。因此，即使相邻两个哈希的差值很小，也只会产生五分之一效应的分配数量差；一个节点崩溃时，其五个虚拟节点向顺时针方向传递压力，这会很均匀地将压力传递给另外两个节点。

分配的时间复杂度为O(log(n))。

### singleflight优化GET请求

GET操作使用singleflight进行优化。如果同时（第一个请求从发起到返回期间）有100个GET请求都要获取同一个key的值，那么实际上只有一个请求被真正发出；当该请求被返回时，想要这个key的所有GET请求都会同时获得结果。这大大减少了查找时产生的请求量，防止高频读造成的资源挤占与崩溃。

## node

获取到参数后，令此请求排队，排到后将其传入lru层进行lru处理，lru操作存储层。

### 请求排队

所有请求都要获取一个mutex才能接着执行。Golang的mutex有正常模式和饥饿模式的切换机制，因此当请求量不低时，相当于FIFO调度，可以避免活锁问题。

接下来全过程都持有此时获取到的mutex，因此不用担心临界区问题。

### 存储层

所有数据以双向链表的形式存在堆内存中，存储层封装了此链表。当一个key-value被添加时，将其进行包装后添加到链表。

```go
//数据会被包装为Element（链表项类型），包含了key和value
type Element struct {  
   Key   string  
   Value Data  
   Pre   *Element  
   Next  *Element  
}
```

### lru层

此层可视为对存储层的包装。

#### HashMap

lru层维护一个HashMap，将key映射到链表项地址，因此可以在得到key后以O(1)的时间找到链表的某一项。

HashMap使得所有数据操作的时间复杂度都为O(1)。

#### lru逻辑

由于node存储量有上限，而且需求中允许适当地删除老数据，因此使用LRU逻辑（最近最少使用/最不近使用）进行管理：当存储的数据总量（所有value的存储空间的和）超出指定的上限时，删除最长时间未被访问的结点。

于是，lru层以如下逻辑调用HashMap与存储层：

- GET: 在HashMap中检索key
	- 若不存在，返回异常；
	- 若存在，则将该链表项移至链表首部，并返回值。
- PUT: 在HashMap中检索key
	- 若不存在key，则视作插入，将value添加到链表首部，并在HashMap中添加一项(key,\*element)，其中element是指向该链表项的指针。
	- 若存在key，则视作修改，更新链表项的数据值，并且将该链表项移至链表首部；
	- 数据总量超过上限时，不断删除链表尾部的数据项和对应的HashMap项（从数据项中获取key值），直到数据总量低于上限。
- DELETE: 在HashMap中检索key
	- 若不存在，返回异常；
	- 若存在，则删除该链表项，并删除HashMap中的key项




















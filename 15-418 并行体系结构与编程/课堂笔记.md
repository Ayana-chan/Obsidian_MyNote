


# 基础

A **parallel computer** is <u>a collection of</u> **processing elements** that <u>cooperate</u> to solve problems <u>quickly</u>

加速比定义：
$$speedup_P=\frac{execute\_time_{1}}{execute\_time_{P}}$$ 

# Lec2 Modern Multicore Processor

ILP: Instruction Level Parallelism

vector: 例如，把八个数据和其他地方的八个数据加在一起生成八个数据，则称数据被聚合为向量。

比如，要对一个数组的每一项都完全独立地执行一个操作，则可以让八个元素一起被拿出来，然后一起被执行一样的流程操作。

SIMD扩展（AVX intrinsics）：对advanced vector的支持。xmm寄存器是特殊的256bit（32Byte）寄存器，有完全不同的指令集。

>SIMD(Single Instruction Multiple Data)（读作same D）即单指令流多数据流，是一种采用一个控制器来控制多个处理器，同时对一组数据（又称“数据向量”）中的每一个分别执行相同的操作从而实现空间上的并行性的技术。简单来说就是一个指令能够同时处理多个数据。

>ps = pack single

![](assets/uTools_1698031596956.png)

当各个数据的操作存在分支，即操作方式不一样时，可以使用mask来实现分支，“X”表示当前不对该数据进行操作。

![](assets/uTools_1698037591707.png)

- converge: 都做同一件事，从而能最大利用。SIMD追求converge。
- diverge: 分歧。

- **explicit SIMD**: SIMD parallelization is performed at compile time. Can inspect program binary and see instructions(vstoreps,vmulps,etc.)
- **Implicit SIMD**:
	- Compiler generates a scalar binary(scalar instructions). 
	- But N instances of the program are always run together on the processor. `execute(my_function,N); //execute my_function N times`
	- In other words,the interface to the hardware itself is data-parallel.
	- Hardware(not compiler)is responsible for simultaneously executing the same instruction from multiple instances on different data on SIMD ALUs

SIMD width: 可处理的数据量（不是字节数），8~32，一般为32。

stall: 发生数据相关时，会导致运行暂停。而stall的来源的大头是内存访问。内存传输过慢，会生成较大的latency。而cache可以减少暂停的时间（latency）。**prefetch**将数据提前放到cache里面也可以减少stall。

使用**multi-threading**可以在不同thread的stall期间执行其他thread的指令；可以直接在cache-L1里面存thread execution context；线程多的时候hide stall的能力会更强。`hyper-threading`: CPU给多个线程分配不同的寄存器组，实现无需上下文切换的多线程。

Execution Unit用于根据相关性协调决定多个thread的运作方式（顺序）：
![](assets/uTools_1698041113102.png)

GPU尽力拉高吞吐量，来hide latency，达成极高的并发度；缩小cache来把更多空间用于ALU。
![](assets/uTools_1698041605328.png)


# Lec3 Parallel Programming Abstractions

## ISPC (Intel SPMD Program Compiler)

- ISPC: Intel SPMD Program Compiler，一种语言
- SPMD: single program multiple data，同代码块不同数据
- http://ispc.github.com/

**ISPC会编译出SIMD指令**。SPMD是model，SIMD是implement。由于使用SIMD来增加并发性，因此实际上是单线程的。

![](assets/uTools_1699235617168.png)

ISPC Keywords:
**programCount**: number of simultaneously executing instances in the gang(uniform value). 决定了并发量。
**programIndex**: id of the current instance in the gang.(a non-uniform value:"varying"). 并发的每个程序（instance）都具有不同的programIndex。$[0,programCount)$
**uniform**: A type modifier.All instances have the same value for this variable.Its use is purely an optimization.Not needed for correctness. 标记对并发的每个程序都等同的变量，用于优化。

### interleaved & blocked

**interleaved assignment**: 每个instance的任务是分散的，因此并发时，每个instance完成一个任务后，得到的结果是连续的。（是上面的ISPC代码所决定的）
![](assets/uTools_1699236729496.png)
![](assets/uTools_1699237488010.png)

**blocked assignment**: 每个instance的任务是连续的，但并发的所有instance的第一个任务是分散的。
![400](assets/uTools_1699236964851.png)
![](assets/uTools_1699237112195.png)

**interleaved比blocked更优越**，因为它每次都会得到**连续的结果**，而SIMD会把这结果放进**向量寄存器**，如果寄存器内数据是连续的话可以增加效率。blocked需要存储不连续的向量，会消耗更多CPU周期。（blocked看起来对cache更友好，但由于ISPC仅仅是单线程，因此无大用）

### foreach

可以直接使用foreach，将interleaved & blocked的选择交给编译器：
![](assets/uTools_1699238004114.png)

### reduction

求和时，因为结果是共享、可写的，因此标为uniform会编译出错。

解决方法：定义非uniform的partial变量（这会导致foreach出来的所有instance都具有私有、独立的partial。计算完毕后，调用reduce_add就可以将各个instance的partial给加起来）。
![](assets/uTools_1699238710685.png)


## Three Model

![](assets/uTools_1699250216958.png)

![](assets/uTools_1699252280741.png)

Use shared address space programming within a multi-core node of a cluster,use message passing between nodes

### Shared address space model

**Symmetric(shared-memory) multi-processor(SMP)**:
- Uniform memory access time: cost of accessing an uncached 
- memory address is the same for all processors
- **low scalability**

![400](assets/uTools_1699249111988.png)
![400](assets/uTools_1699249145780%201.png)


**Non-uniform memory access (NUMA)**: 
- All processors can access any memory location
- the cost of memory access (latency and/or bandwidth) is **different** for different processors
- **high scalability**
- 处理器旁边就有Memory，同时也能较高延迟地访问其他内存

![](assets/uTools_1699249008905.png)

NUMA可以在本地保存运行栈等其他处理器不需要的数据，同时在并发的时候其他处理器不处理的数据也能完全放在本地执行。

### Message passing model

两个线程独立运行，有自己的私有空间，互相之间唯一的交流方式是send/receive message。

MPI: message passing interface

不要求机器实现共享l/s功能，只需要能传递消息。可以用于大型机间传递信息。

### Data-parallel model

**Basic structure**: map a function onto a large collection of data
- Functional:side-effect free execution
- No communication among distinct function invocations (allow invocations to be scheduled in any order,including in parallel)

以前是用vector运算，但现在都是SPMD了。

ISPC中，编程可能会出现不确定性（并行的instance的结果写在同一个地方）。因此要使用更正规的编程方式来避免这些谬误。

functional form: **stream programing model**
- Streams:collections of elements. Elements can be processed independently.
- Kernels:side-effect-free functions. Operate element-wise on collections.

![](assets/uTools_1699250968532.png)
![](assets/uTools_1699251173848.png)

但有一个缺点是，中间这个tmp流在处理过程中不一定有必要，当过程太多的时候可能会需要创建极多的流，造成浪费。最好可以有某种方式把foo和bar整合起来。

gather修改取值来源逻辑，scatter修改赋值目标逻辑。indices是索引流，表示数据位置，将input的按照索引重排列为tmp_input以load，或将output重排列为tmp_input以store，且不发生复制。
![](assets/uTools_1699251617976.png)

![](assets/uTools_1699251956629.png)


# Lec4 Parallel Programming Basics






















